{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Debug Test Script EnergyDiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from src.opensynth.data_modules.lcl_data_module import LCLDataModule, LCLData\n",
    "from src.opensynth.models.energydiff import diffusion, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LCLDataModuleWithValidation(LCLDataModule):\n",
    "    def __init__(self, data_path, stats_path, batch_size=32, n_samples=1000, outlier_path=None, n_val_samples=200):\n",
    "        super().__init__(data_path, stats_path, batch_size, n_samples, outlier_path=outlier_path)\n",
    "        self.n_val_samples = n_val_samples\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        super().setup(stage)\n",
    "        self.val_dataset = LCLData(\n",
    "            data_path=self.data_path,\n",
    "            stats_path=self.stats_path,\n",
    "            n_samples=self.n_val_samples,\n",
    "            outlier_path=self.outlier_path,\n",
    "        )\n",
    "        \n",
    "    def val_dataloader(self):\n",
    "        return torch.utils.data.DataLoader(\n",
    "            self.val_dataset,\n",
    "            self.batch_size,\n",
    "            drop_last=True,\n",
    "            shuffle=False,\n",
    "        )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep data\n",
    "data_path = Path(\"data/processed/historical/train/lcl_data.csv\")\n",
    "stats_path = Path(\"data/processed/historical/train/mean_std.csv\")\n",
    "outlier_path = Path(\"data/processed/historical/train/outliers.csv\")\n",
    "\n",
    "dm = LCLDataModuleWithValidation(\n",
    "    data_path=data_path,\n",
    "    stats_path=stats_path,\n",
    "    batch_size=200,\n",
    "    n_samples=2000,\n",
    ")\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fake data\n",
    "def get_noisy_sin(n_samples):\n",
    "    x = np.linspace(0, 3/2 * np.pi, 48)\n",
    "    samples = []\n",
    "    for _ in range(n_samples):\n",
    "        phase = np.random.uniform(0, 2 * np.pi)\n",
    "        y = np.sin(x + phase) + np.random.normal(0, 0.01, x.shape)\n",
    "        samples.append(y)\n",
    "    return {\n",
    "        'kwh': torch.from_numpy(np.array(samples)).float(), \n",
    "        'features': torch.from_numpy(x).float()\n",
    "    }\n",
    "    \n",
    "class SinDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, n_samples=1000):\n",
    "        self.data = get_noisy_sin(n_samples)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data['kwh'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'kwh': self.data['kwh'][idx],\n",
    "            'features': self.data['features']\n",
    "        }\n",
    "\n",
    "class SinDataModule(pl.LightningDataModule):\n",
    "    def __init__(self, n_samples=1000, batch_size=32, n_val_samples=0):\n",
    "        super().__init__()\n",
    "        self.n_samples = n_samples\n",
    "        self.n_val_samples = n_val_samples\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        self.train_dataset = SinDataset(self.n_samples)\n",
    "        self.val_dataset = SinDataset(self.n_val_samples)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        dataset = self.train_dataset\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=self.batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        dataset = self.val_dataset\n",
    "        return torch.utils.data.DataLoader(dataset, batch_size=self.batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dm = SinDataModule(n_samples=1000, batch_size=200, n_val_samples=600)\n",
    "# dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prep model\n",
    "df_model = diffusion.PLDiffusion1D(\n",
    "    dim_base=128,\n",
    "    dim_in=1,\n",
    "    num_attn_head=4,\n",
    "    num_decoder_layer=12,\n",
    "    dim_feedforward=512,\n",
    "    dropout=0.1,\n",
    "    learn_variance=False,\n",
    "    num_timestep=500,\n",
    "    model_mean_type=diffusion.ModelMeanType.V,\n",
    "    model_variance_type=diffusion.ModelVarianceType.FIXED_SMALL,\n",
    "    loss_type=diffusion.LossType.MSE,\n",
    "    beta_schedule_type=diffusion.BetaScheduleType.COSINE,\n",
    "    lr=1e-3,\n",
    "    ema_update_every=1,\n",
    "    ema_decay=0.99,\n",
    ")\n",
    "trainer = pl.Trainer(\n",
    "    gradient_clip_val=1.0,\n",
    "    gradient_clip_algorithm=\"norm\",\n",
    "    max_epochs=500,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_model = diffusion.PLDiffusion1D.load_from_checkpoint('lightning_logs/version_38/checkpoints/epoch=1-step=20.ckpt',)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training\n",
    "trainer.fit(df_model, dm,\n",
    "            ckpt_path='lightning_logs/version_38/checkpoints/epoch=1-step=20.ckpt', # optional. ALSO resumes the model, along with training state\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_dir = trainer.logger.log_dir\n",
    "metrics = pd.read_csv(f\"{log_dir}/metrics.csv\")\n",
    "epoch_train_loss = metrics['train_loss_epoch'].dropna().values\n",
    "epoch_val_loss = metrics['val_loss'].dropna().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(epoch_train_loss, label='Training Loss')\n",
    "plt.plot(epoch_val_loss, label='Validation Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample\n",
    "ema_df_model = df_model.ema.ema_model # GaussianDiffusion1D\n",
    "ans_samples = ema_df_model.ancestral_sample(50, 50, 48, 1)\n",
    "dpm_samples = ema_df_model.dpm_solver_sample(50, 50, 100, (48, 1))\n",
    "true_samples = dm.dataset[0:50]['kwh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(dpm_samples.mean(dim=0).cpu().numpy(), label='DPM Solver')\n",
    "plt.plot(ans_samples.mean(dim=0).cpu().numpy(), label='Ancestral Sampling')\n",
    "plt.plot(true_samples.mean(dim=0).cpu().numpy(), label='True')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "for idx in range(min(ans_samples.shape[0], 25)):\n",
    "    axs[0].plot(ans_samples[idx].detach().cpu().numpy(), linestyle='-.', label=\"ancestral\" if idx == 0 else None)\n",
    "axs[0].set_title('Ancestral Sampling')\n",
    "axs[0].legend()\n",
    "\n",
    "for idx in range(min(dpm_samples.shape[0], 25)):\n",
    "    axs[1].plot(dpm_samples[idx].detach().cpu().numpy(), linestyle=':', label=\"dpm\" if idx == 0 else None)\n",
    "axs[1].set_title('DPM Solver')\n",
    "axs[1].legend()\n",
    "\n",
    "for idx in range(min(true_samples.shape[0], 25)):\n",
    "    axs[2].plot(true_samples[idx].detach().cpu().numpy(), label=\"true\" if idx == 0 else None)\n",
    "axs[2].set_title('True Samples')\n",
    "axs[2].legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "pass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opensynth-dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
