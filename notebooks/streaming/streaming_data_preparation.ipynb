{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Streaming - Data Preparation \n",
    "\n",
    "In order to be able to train Faraday by streaming training data (necessary if your dataset is too large to fit in memory), then you need to prepare the dataset for streaming.\n",
    "\n",
    "- For more information on the package we use to implement streaming (Litdata), please refer to the [docs](https://github.com/Lightning-AI/litdata)\n",
    "- The litdata dataset transformation documentation can be found [here](https://github.com/Lightning-AI/litdata)\n",
    "\n",
    "### Pre-requisites\n",
    "\n",
    "1. If you haven't already, please download LCL dataset from [data.london.gov.uk](https://data.london.gov.uk/dataset/smartmeter-energy-use-data-in-london-households), or...\n",
    "2. Use the cli app to download and prepare the data (see README)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from litdata import optimize\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import torch\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "\n",
    "from opensynth.data_modules.lcl_data_module import TrainingData\n",
    "\n",
    "RANDOM_STATE = 0\n",
    "OUTPUT_DIR = Path(\"../../data/processed/historical/stream\")\n",
    "SIZE_LIMIT = \"100mb\"   # size of each chunk pre-compression\n",
    "COMPRESSION = \"zstd\"   # compression algorithm\n",
    "NUM_WORKERS = 4        # number of workers for parallel processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üíø Loading LCL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"../../data/processed/historical/train/lcl_data.csv\")\n",
    "stats_path = Path(\"../../data/processed/historical/train/mean_std.csv\")\n",
    "outlier_path = Path(\"../../data/processed/historical/train/outliers.csv\")\n",
    "\n",
    "data = pd.read_csv(data_path)\n",
    "outliers = pd.read_csv(outlier_path)\n",
    "\n",
    "# Combine and shuffle data\n",
    "df = pd.concat([data, outliers])\n",
    "df = df.sample(\n",
    "    frac=1, random_state=RANDOM_STATE\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Work out some stats to partition the source data\n",
    "# Note: this is not strictly necessary for the LCL data as it is so small\n",
    "# but I'm showing the process here as it is necessary for larger datasets\n",
    "\n",
    "NUM_GROUPS = 5\n",
    "GROUP_SIZE = len(df) // NUM_GROUPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the function that will be called by litdata.optimize to yield the data in the correct format\n",
    "# Some things to take into account:\n",
    "# - Optimize supports parallel processing, so we pass in a range of values that allow us to slice the data\n",
    "# - Our streaming dataloaders expect the data to be in a particular format (TrainingData)\n",
    "\n",
    "def yield_data(idx: int):\n",
    "    data_slice = df.iloc[idx * GROUP_SIZE: (idx + 1) * GROUP_SIZE]\n",
    "\n",
    "    for row in data_slice.itertuples():\n",
    "        features: dict[str, torch.Tensor] = {\n",
    "            \"month\": getattr(row, \"month\"),\n",
    "            \"dayofweek\": getattr(row, \"dayofweek\"),\n",
    "        }\n",
    "        yield TrainingData(\n",
    "            kwh=getattr(row, \"kwh\"),\n",
    "            features=features,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Optimize into streaming format\n",
    "\n",
    "Docs for the optimize function are [here](https://github.com/Lightning-AI/litdata/blob/cedc6a663ace221a98aa422cbc095055cb9fd43e/src/litdata/processing/functions.py#L295)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create an account on https://lightning.ai/ to optimize your data faster using multiple nodes and large machines.\n",
      "Setting multiprocessing start_method to fork. Tip: Libraries relying on lock can hang with `fork`. To use `spawn` in notebooks, move your code to files and import it within the notebook.\n",
      "Storing the files under /Users/gus.chadney/dev/OpenSynth/data/processed/historical/stream\n",
      "Setup started with fast_dev_run=False.\n",
      "Setup finished in 0.004 seconds. Found 5 items to process.\n",
      "Starting 4 workers with 5 items. The progress bar is only updated when a worker finishes.\n",
      "Rank 0 inferred the following `['str', 'int', 'int']` data format.Rank 1 inferred the following `['str', 'int', 'int']` data format.\n",
      "\n",
      "Rank 2 inferred the following `['str', 'int', 'int']` data format.Workers are ready ! Starting data processing...\n",
      "\n",
      "Rank 3 inferred the following `['str', 'int', 'int']` data format."
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8dcf6baa59bc4386a3767da5d0c38362",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Progress:   0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Worker 0 is terminating.\n",
      "Worker 1 is terminating.\n",
      "Worker 2 is terminating.\n",
      "Worker 0 is done.\n",
      "Worker 1 is done.\n",
      "Worker 2 is done.\n",
      "Worker 3 is terminating.\n",
      "Worker 3 is done.\n",
      "Workers are finished.\n",
      "Finished data processing!\n"
     ]
    }
   ],
   "source": [
    "optimize(\n",
    "    fn=yield_data,\n",
    "    inputs=list(range(NUM_GROUPS)),\n",
    "    output_dir=str(OUTPUT_DIR),\n",
    "    num_workers=NUM_WORKERS,\n",
    "    chunk_bytes=SIZE_LIMIT,\n",
    "    compression=COMPRESSION,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSynth-n2CNCCrk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
