{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_data = pd.read_csv(\"../../data/processed/historical/train/lcl_data.csv\")\n",
    "df_25K = full_data.sample(25000, random_state=0)\n",
    "df_25K.to_csv(\"../../data/processed/historical/train/lcl_data_25K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "RANDOM_STATE = 0\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(RANDOM_STATE)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from opensynth.data_modules.lcl_data_module import LCLDataModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = Path(\"../../data/processed/historical/train/lcl_data_25K.csv\")\n",
    "stats_path = Path(\"../../data/processed/historical/train/mean_std.csv\")\n",
    "outlier_path = Path(\"../../data/processed/historical/train/outliers.csv\")\n",
    "\n",
    "dm = LCLDataModule(data_path=data_path, stats_path=stats_path, batch_size=25000, n_samples=25000)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2x1gj41j1xb5z153q5m_4rn80000gn/T/ipykernel_99151/2311655816.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  vae_model = torch.load(\"vae_model.pt\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "FaradayVAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder_layers): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=32, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (latent): Linear(in_features=18, out_features=16, bias=True)\n",
       "    (latent_activations): GELU(approximate='none')\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=512, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (reparametriser): ReparametrisationModule(\n",
       "    (mean): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from opensynth.models.faraday import FaradayVAE\n",
    "vae_model = torch.load(\"vae_model.pt\")\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensynth.models.faraday.gaussian_mixture.prepare_gmm_input import encode_data_for_gmm\n",
    "\n",
    "next_batch = next(iter(dm.train_dataloader()))\n",
    "input_tensor = encode_data_for_gmm(data=next_batch, vae_module=vae_model)\n",
    "input_data = input_tensor.detach().numpy()\n",
    "n_samples = len(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 250\n",
    "REG_COVAR = 1e-4\n",
    "EPOCHS = 25\n",
    "IDX = 0\n",
    "CONVERGENCE_TOL = 1e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0195, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm import gmm_utils\n",
    "\n",
    "labels_, means_, responsibilities_ = gmm_utils.initialise_centroids(\n",
    "        X=input_data, n_components=N_COMPONENTS\n",
    "    )\n",
    "print(labels_.dtype, responsibilities_.dtype, means_.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1549)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "print(gmm_init_params[\"precision_cholesky\"][IDX][0][0])\n",
    "print(gmm_init_params[\"weights\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [00:05<00:01,  3.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converged: True. Number of iterations: 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params, training_loop\n",
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureModel\n",
    "\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "torch_gmm = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "torch_gmm.initialise(gmm_init_params)\n",
    "trained_model = training_loop(model=torch_gmm, data=input_tensor, max_iter=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from scipy import linalg\n",
    "\n",
    "def _estimate_gaussian_parameters(X, resp, reg_covar=REG_COVAR):\n",
    "    nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "    n_components, n_features = means.shape\n",
    "    covariances = np.empty((n_components, n_features, n_features))\n",
    "    for k in range(n_components):\n",
    "        diff = X - means[k]\n",
    "        covariances[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]\n",
    "        covariances[k].flat[:: n_features + 1] += reg_covar\n",
    "    return nk, means, covariances\n",
    "\n",
    "def _compute_precision_cholesky(covariances):\n",
    "    estimate_precision_error_message = (\n",
    "        \"Fitting the mixture model failed because some components have \"\n",
    "        \"ill-defined empirical covariance (for instance caused by singleton \"\n",
    "        \"or collapsed samples). Try to decrease the number of components, \"\n",
    "        \"or increase reg_covar.\"\n",
    "    )\n",
    "\n",
    "    n_components, n_features, _ = covariances.shape\n",
    "    precisions_chol = np.empty((n_components, n_features, n_features))\n",
    "    for k, covariance in enumerate(covariances):\n",
    "        try:\n",
    "            cov_chol = linalg.cholesky(covariance, lower=True)\n",
    "        except linalg.LinAlgError:\n",
    "            raise ValueError(estimate_precision_error_message)\n",
    "        precisions_chol[k] = linalg.solve_triangular(\n",
    "            cov_chol, np.eye(n_features), lower=True\n",
    "        ).T\n",
    "    return precisions_chol\n",
    "\n",
    "def _compute_log_det_cholesky(matrix_chol, n_features):\n",
    "    n_components, _, _ = matrix_chol.shape\n",
    "    log_det_chol = np.sum(\n",
    "        np.log(matrix_chol.reshape(n_components, -1)[:, :: n_features + 1]), 1\n",
    "    )\n",
    "    return log_det_chol\n",
    "\n",
    "def _estimate_log_gaussian_prob(X, means, precisions_chol):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_components, _ = means.shape\n",
    "\n",
    "    log_det = _compute_log_det_cholesky(precisions_chol, n_features)\n",
    "\n",
    "    log_prob = np.empty((n_samples, n_components))\n",
    "    for k, (mu, prec_chol) in enumerate(zip(means, precisions_chol)):\n",
    "        y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n",
    "        log_prob[:, k] = np.sum(np.square(y), axis=1)\n",
    "    return -0.5 * (n_features * np.log(2 * np.pi) + log_prob) + log_det\n",
    "\n",
    "def _estimate_log_weights(weights):\n",
    "        return np.log(weights)\n",
    "\n",
    "def _estimate_weighted_log_prob(X, means, precisions_chol, weights):\n",
    "        return _estimate_log_gaussian_prob(X, means, precisions_chol) + _estimate_log_weights(weights)\n",
    "\n",
    "\n",
    "def _estimate_log_prob_resp(X, means, precisions_chol, weights):\n",
    "    weighted_log_prob = _estimate_weighted_log_prob(X, means, precisions_chol, weights)\n",
    "    log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
    "    with np.errstate(under=\"ignore\"):\n",
    "        log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]\n",
    "    return log_prob_norm, log_resp\n",
    "\n",
    "def _e_step(X,means, precisions_chol, weights):\n",
    "    log_prob_norm, log_resp = _estimate_log_prob_resp(X, means, precisions_chol, weights)\n",
    "    return np.mean(log_prob_norm), log_resp\n",
    "\n",
    "def _m_step(X, log_reponsibilities, reg_covar=REG_COVAR):\n",
    "\n",
    "    weights_, means_, covariances_ = _estimate_gaussian_parameters(X,np.exp(log_reponsibilities),reg_covar=reg_covar)\n",
    "    weights_ /= weights_.sum()\n",
    "\n",
    "    precision_cholesky_ = _compute_precision_cholesky(covariances=covariances_)\n",
    "\n",
    "    return precision_cholesky_, weights_, means_, covariances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 4.167169570922852. Initial mean: 0.18039406836032867\n",
      "Old Prec Chol: 4.167169570922852. Old means: 0.18039406836032867\n",
      "New prec chol: 4.233167242590703. New means: 0.1601667862775156\n",
      "Change: inf\n",
      "Old Prec Chol: 4.233167242590703. Old means: 0.1601667862775156\n",
      "New prec chol: 4.302608211404412. New means: 0.13654736888632887\n",
      "Change: 0.5965802676941183\n",
      "Old Prec Chol: 4.302608211404412. Old means: 0.13654736888632887\n",
      "New prec chol: 4.170436562212954. New means: 0.11592101725647623\n",
      "Change: 0.23705405366639276\n",
      "Old Prec Chol: 4.170436562212954. Old means: 0.11592101725647623\n",
      "New prec chol: 3.935564560399703. New means: 0.0963309089718066\n",
      "Change: 0.15404550009157947\n",
      "Old Prec Chol: 3.935564560399703. Old means: 0.0963309089718066\n",
      "New prec chol: 3.804755944723549. New means: 0.08183459658313541\n",
      "Change: 0.11730303257668773\n",
      "Old Prec Chol: 3.804755944723549. Old means: 0.08183459658313541\n",
      "New prec chol: 3.7495639777909733. New means: 0.06969489063703525\n",
      "Change: 0.09750155304139752\n",
      "Old Prec Chol: 3.7495639777909733. Old means: 0.06969489063703525\n",
      "New prec chol: 3.698762907072338. New means: 0.062310893371045534\n",
      "Change: 0.08568762028393984\n",
      "Old Prec Chol: 3.698762907072338. Old means: 0.062310893371045534\n",
      "New prec chol: 3.687402821953369. New means: 0.05839759908817587\n",
      "Change: 0.07524498393576817\n",
      "Old Prec Chol: 3.687402821953369. Old means: 0.05839759908817587\n",
      "New prec chol: 3.7070089226903407. New means: 0.052722860616647195\n",
      "Change: 0.059725913120262764\n",
      "Old Prec Chol: 3.7070089226903407. Old means: 0.052722860616647195\n",
      "New prec chol: 3.751322771815784. New means: 0.04360956904979352\n",
      "Change: 0.048979238381453905\n",
      "Old Prec Chol: 3.751322771815784. Old means: 0.04360956904979352\n",
      "New prec chol: 3.835909185705686. New means: 0.03140907325977023\n",
      "Change: 0.041440076983920826\n",
      "Old Prec Chol: 3.835909185705686. Old means: 0.03140907325977023\n",
      "New prec chol: 3.8816855621379824. New means: 0.021332017869665626\n",
      "Change: 0.032894460435271666\n",
      "Old Prec Chol: 3.8816855621379824. Old means: 0.021332017869665626\n",
      "New prec chol: 3.8768451472675145. New means: 0.015276416859914958\n",
      "Change: 0.027275442050531007\n",
      "Old Prec Chol: 3.8768451472675145. Old means: 0.015276416859914958\n",
      "New prec chol: 3.8660698813739316. New means: 0.010747871820835456\n",
      "Change: 0.022602750148683737\n",
      "Old Prec Chol: 3.8660698813739316. Old means: 0.010747871820835456\n",
      "New prec chol: 3.8495421250771904. New means: 0.005760667204606461\n",
      "Change: 0.01933222411794222\n",
      "Old Prec Chol: 3.8495421250771904. Old means: 0.005760667204606461\n",
      "New prec chol: 3.8257802006147066. New means: 0.0006028443869305826\n",
      "Change: 0.01633507269275769\n",
      "Old Prec Chol: 3.8257802006147066. Old means: 0.0006028443869305826\n",
      "New prec chol: 3.8076944788141853. New means: -0.003792840335581965\n",
      "Change: 0.013589493047765244\n",
      "Old Prec Chol: 3.8076944788141853. Old means: -0.003792840335581965\n",
      "New prec chol: 3.8070962748787194. New means: -0.007622690567166655\n",
      "Change: 0.01152340643476546\n",
      "Old Prec Chol: 3.8070962748787194. Old means: -0.007622690567166655\n",
      "New prec chol: 3.8225880878924396. New means: -0.011018136901938985\n",
      "Change: 0.010400725244114839\n",
      "Old Prec Chol: 3.8225880878924396. Old means: -0.011018136901938985\n",
      "New prec chol: 3.8459171846291267. New means: -0.015152618092952883\n",
      "Change: 0.00888319882383426\n",
      "Converged: True. Number of iterations: 19\n"
     ]
    }
   ],
   "source": [
    "means = gmm_init_params[\"means\"].detach().numpy()\n",
    "weights = gmm_init_params[\"weights\"].detach().numpy()\n",
    "prec_chol = gmm_init_params[\"precision_cholesky\"].detach().numpy()\n",
    "\n",
    "print(f\"Initial prec chol: {prec_chol[IDX][0][0]}. Initial mean: {means[IDX][0]}\")\n",
    "\n",
    "converged = False\n",
    "lower_bound = -np.inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    prev_lower_bound = lower_bound\n",
    "\n",
    "    print(f\"Old Prec Chol: {prec_chol[IDX][0][0]}. Old means: {means[IDX][0]}\")\n",
    "    log_prob, log_resp = _e_step(input_data, means, prec_chol, weights)\n",
    "    prec_chol, weights, means, covar = _m_step(input_data, log_resp)\n",
    "\n",
    "    print(f\"New prec chol: {prec_chol[IDX][0][0]}. New means: {means[IDX][0]}\")\n",
    "\n",
    "    # Converegence\n",
    "    lower_bound = log_prob\n",
    "    change = abs(lower_bound - prev_lower_bound)\n",
    "    print(f\"Change: {change}\")\n",
    "    if change < CONVERGENCE_TOL:\n",
    "        converged = True\n",
    "        break\n",
    "\n",
    "print(f'Converged: {converged}. Number of iterations: {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 1\t time lapse 4.62847s\t ll change inf\n",
      "  Iteration 2\t time lapse 1.85284s\t ll change 0.55613\n",
      "  Iteration 3\t time lapse 2.02959s\t ll change 0.24395\n",
      "  Iteration 4\t time lapse 2.55099s\t ll change 0.16258\n",
      "  Iteration 5\t time lapse 1.87178s\t ll change 0.12128\n",
      "  Iteration 6\t time lapse 2.08313s\t ll change 0.10104\n",
      "  Iteration 7\t time lapse 2.50615s\t ll change 0.08843\n",
      "  Iteration 8\t time lapse 1.86207s\t ll change 0.07718\n",
      "  Iteration 9\t time lapse 2.06804s\t ll change 0.05981\n",
      "  Iteration 10\t time lapse 2.38199s\t ll change 0.04918\n",
      "  Iteration 11\t time lapse 3.36751s\t ll change 0.04353\n",
      "  Iteration 12\t time lapse 2.49519s\t ll change 0.03475\n",
      "  Iteration 13\t time lapse 3.39737s\t ll change 0.02870\n",
      "  Iteration 14\t time lapse 2.85775s\t ll change 0.02447\n",
      "  Iteration 15\t time lapse 2.45130s\t ll change 0.02136\n",
      "  Iteration 16\t time lapse 2.24533s\t ll change 0.01721\n",
      "  Iteration 17\t time lapse 2.86297s\t ll change 0.01443\n",
      "  Iteration 18\t time lapse 2.75476s\t ll change 0.01313\n",
      "  Iteration 19\t time lapse 2.98449s\t ll change 0.01219\n",
      "  Iteration 20\t time lapse 2.87185s\t ll change 0.01051\n",
      "  Iteration 21\t time lapse 3.23096s\t ll change 0.00992\n",
      "Initialization converged. time lapse 55.35578s\t lower bound 0.07303.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "init_weights = gmm_init_params[\"weights\"]\n",
    "init_means = gmm_init_params[\"means\"]\n",
    "\n",
    "skgmm = GaussianMixture(n_components=N_COMPONENTS, covariance_type='full', tol=CONVERGENCE_TOL, max_iter=EPOCHS, random_state=0, means_init = init_means, weights_init=init_weights, verbose=2, verbose_interval=1)\n",
    "skgmm.fit(input_data)\n",
    "skgmm_pred = skgmm.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 21)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm.converged_, skgmm.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_tensor: torch.Tensor):\n",
    "        self.data = data_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "class CustomDataModule(LightningDataModule):\n",
    "    def __init__(self, data_tensor: torch.Tensor, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.data_tensor = data_tensor\n",
    "        self.batch_size = batch_size\n",
    "    def setup(self, stage=\"\"):\n",
    "        self.custom_ds = CustomDataset(self.data_tensor)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.custom_ds, batch_size=self.batch_size, shuffle=False, generator=g, worker_init_fn=seed_worker)\n",
    "    \n",
    "custom_dm = CustomDataModule(data_tensor=input_tensor, batch_size=25000)\n",
    "custom_dm.setup(stage=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(next(iter(custom_dm.train_dataloader()))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name       | Type                 | Params | Mode \n",
      "------------------------------------------------------------\n",
      "0 | gmm_module | GaussianMixtureModel | 0      | train\n",
      "1 | vae_module | FaradayVAE           | 402 K  | eval \n",
      "------------------------------------------------------------\n",
      "402 K     Trainable params\n",
      "0         Non-trainable params\n",
      "402 K     Total params\n",
      "1.609     Total estimated model params size (MB)\n",
      "1         Modules in train mode\n",
      "32        Modules in eval mode\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 4.167169570922852. Initial mean: 0.18039406836032867\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] Encoded batch: 0.019506216049194336,Means: 0.16016706824302673\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.13565151393413544\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.11374605447053909\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.09664156287908554\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.08267594128847122\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.0698365718126297\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.06141422316431999\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.05523926019668579\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.04798334836959839\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.03951813653111458\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]       Encoded batch: 0.019506216049194336,Means: 0.03245989978313446\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.028810160234570503\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.02723531611263752\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.02634807676076889\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.025478104129433632\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.02355583757162094\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.020092351362109184\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.01481642946600914\n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.007346019148826599\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: 0.0009641501819714904\n",
      "Epoch 20:   0%|          | 0/1 [00:00<?, ?it/s, v_num=20]        Encoded batch: 0.019506216049194336,Means: -0.0038476798217743635\n",
      "Epoch 20: 100%|██████████| 1/1 [00:00<00:00,  2.95it/s, v_num=20]\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureLightningModule\n",
    "gmm_module = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "gmm_module.initialise(gmm_init_params)\n",
    "print(f\"Initial prec chol: {gmm_module.precision_cholesky[IDX][0][0]}. Initial mean: {gmm_module.means[IDX][0]}\")\n",
    "\n",
    "gmm_lightning_module = GaussianMixtureLightningModule(\n",
    "    gmm_module = gmm_module,\n",
    "    vae_module = vae_model,\n",
    "    num_components = gmm_module.num_components,\n",
    "    num_features = gmm_module.num_features,\n",
    "    reg_covar = gmm_module.reg_covar,\n",
    "    convergence_tolerance = CONVERGENCE_TOL\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=EPOCHS, accelerator=\"cpu\", deterministic=True )\n",
    "trainer.fit(gmm_lightning_module, custom_dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.040410</td>\n",
       "      <td>-0.015153</td>\n",
       "      <td>-0.003848</td>\n",
       "      <td>-0.003848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.593916</td>\n",
       "      <td>-1.652623</td>\n",
       "      <td>-1.620407</td>\n",
       "      <td>-1.620407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.846162</td>\n",
       "      <td>-0.902899</td>\n",
       "      <td>-0.916207</td>\n",
       "      <td>-0.916207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.532826</td>\n",
       "      <td>1.634990</td>\n",
       "      <td>1.643758</td>\n",
       "      <td>1.643758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.525577</td>\n",
       "      <td>0.576219</td>\n",
       "      <td>0.613053</td>\n",
       "      <td>0.613053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.086819</td>\n",
       "      <td>-0.078370</td>\n",
       "      <td>-0.074405</td>\n",
       "      <td>-0.074405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.543287</td>\n",
       "      <td>-0.597693</td>\n",
       "      <td>-0.581053</td>\n",
       "      <td>-0.581053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.280627</td>\n",
       "      <td>3.354957</td>\n",
       "      <td>3.314699</td>\n",
       "      <td>3.314699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.262851</td>\n",
       "      <td>-0.284911</td>\n",
       "      <td>-0.289358</td>\n",
       "      <td>-0.289358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.726783</td>\n",
       "      <td>-1.837890</td>\n",
       "      <td>-1.762655</td>\n",
       "      <td>-1.762655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.468582</td>\n",
       "      <td>-0.511632</td>\n",
       "      <td>-0.504865</td>\n",
       "      <td>-0.504865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.296969</td>\n",
       "      <td>-1.388875</td>\n",
       "      <td>-1.456079</td>\n",
       "      <td>-1.456079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.326913</td>\n",
       "      <td>-2.370205</td>\n",
       "      <td>-2.409473</td>\n",
       "      <td>-2.409473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.994770</td>\n",
       "      <td>1.007833</td>\n",
       "      <td>1.012981</td>\n",
       "      <td>1.012981</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.146013</td>\n",
       "      <td>1.194739</td>\n",
       "      <td>1.192435</td>\n",
       "      <td>1.192435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.201273</td>\n",
       "      <td>-1.262358</td>\n",
       "      <td>-1.213451</td>\n",
       "      <td>-1.213451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.165138</td>\n",
       "      <td>7.596740</td>\n",
       "      <td>7.431667</td>\n",
       "      <td>7.431667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>3.027587</td>\n",
       "      <td>2.956923</td>\n",
       "      <td>2.869323</td>\n",
       "      <td>2.869323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0  -0.040410 -0.015153 -0.003848  -0.003848\n",
       "1  -1.593916 -1.652623 -1.620407  -1.620407\n",
       "2  -0.846162 -0.902899 -0.916207  -0.916207\n",
       "3   1.532826  1.634990  1.643758   1.643758\n",
       "4   0.525577  0.576219  0.613053   0.613053\n",
       "5  -0.086819 -0.078370 -0.074405  -0.074405\n",
       "6  -0.543287 -0.597693 -0.581053  -0.581053\n",
       "7   3.280627  3.354957  3.314699   3.314699\n",
       "8  -0.262851 -0.284911 -0.289358  -0.289358\n",
       "9  -1.726783 -1.837890 -1.762655  -1.762655\n",
       "10 -0.468582 -0.511632 -0.504865  -0.504865\n",
       "11 -1.296969 -1.388875 -1.456079  -1.456079\n",
       "12 -2.326913 -2.370205 -2.409473  -2.409473\n",
       "13  0.994770  1.007833  1.012981   1.012981\n",
       "14  1.146013  1.194739  1.192435   1.192435\n",
       "15 -1.201273 -1.262358 -1.213451  -1.213451\n",
       "16  7.165138  7.596740  7.431667   7.431667\n",
       "17  3.027587  2.956923  2.869323   2.869323"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_means = pd.DataFrame()\n",
    "df_compare_means[\"skgmm\"] = skgmm.means_[IDX]\n",
    "df_compare_means[\"numpy\"] = means[IDX]\n",
    "df_compare_means[\"torch\"] = trained_model.means[IDX]\n",
    "df_compare_means[\"lightning\"] = gmm_lightning_module.gmm_module.means[IDX]\n",
    "df_compare_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1804, -2.7538, -1.0911,  1.7346,  0.2788, -0.0517, -0.9778,  3.2770,\n",
       "        -0.2799, -2.2817, -0.6563, -1.5545, -1.2570,  0.9383,  0.9554, -2.0788,\n",
       "         5.9050,  3.9497])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_init_params[\"means\"][IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075478</td>\n",
       "      <td>0.067608</td>\n",
       "      <td>0.077627</td>\n",
       "      <td>0.077627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.194839</td>\n",
       "      <td>-0.185708</td>\n",
       "      <td>-0.222430</td>\n",
       "      <td>-0.222430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.110896</td>\n",
       "      <td>-0.103423</td>\n",
       "      <td>-0.099270</td>\n",
       "      <td>-0.099270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111483</td>\n",
       "      <td>0.109388</td>\n",
       "      <td>0.098755</td>\n",
       "      <td>0.098755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.019119</td>\n",
       "      <td>-0.022431</td>\n",
       "      <td>-0.008625</td>\n",
       "      <td>-0.008625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.014319</td>\n",
       "      <td>0.008235</td>\n",
       "      <td>0.015343</td>\n",
       "      <td>0.015343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.137716</td>\n",
       "      <td>-0.139382</td>\n",
       "      <td>-0.117061</td>\n",
       "      <td>-0.117061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.080565</td>\n",
       "      <td>-0.067839</td>\n",
       "      <td>-0.083691</td>\n",
       "      <td>-0.083691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.017084</td>\n",
       "      <td>-0.017829</td>\n",
       "      <td>-0.011237</td>\n",
       "      <td>-0.011237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.040579</td>\n",
       "      <td>-0.060229</td>\n",
       "      <td>-0.044885</td>\n",
       "      <td>-0.044885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.076816</td>\n",
       "      <td>-0.084092</td>\n",
       "      <td>-0.052327</td>\n",
       "      <td>-0.052327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.216567</td>\n",
       "      <td>-0.187606</td>\n",
       "      <td>-0.214062</td>\n",
       "      <td>-0.214062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.211234</td>\n",
       "      <td>0.204352</td>\n",
       "      <td>0.219540</td>\n",
       "      <td>0.219540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.047961</td>\n",
       "      <td>-0.053749</td>\n",
       "      <td>-0.036531</td>\n",
       "      <td>-0.036531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.074849</td>\n",
       "      <td>-0.068122</td>\n",
       "      <td>-0.054252</td>\n",
       "      <td>-0.054252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.148102</td>\n",
       "      <td>-0.142878</td>\n",
       "      <td>-0.170216</td>\n",
       "      <td>-0.170216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.052676</td>\n",
       "      <td>-0.052144</td>\n",
       "      <td>0.021666</td>\n",
       "      <td>0.021666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-0.003426</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>-0.001432</td>\n",
       "      <td>-0.001432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0   0.075478  0.067608  0.077627   0.077627\n",
       "1  -0.194839 -0.185708 -0.222430  -0.222430\n",
       "2  -0.110896 -0.103423 -0.099270  -0.099270\n",
       "3   0.111483  0.109388  0.098755   0.098755\n",
       "4  -0.019119 -0.022431 -0.008625  -0.008625\n",
       "5   0.014319  0.008235  0.015343   0.015343\n",
       "6  -0.137716 -0.139382 -0.117061  -0.117061\n",
       "7  -0.080565 -0.067839 -0.083691  -0.083691\n",
       "8  -0.017084 -0.017829 -0.011237  -0.011237\n",
       "9  -0.040579 -0.060229 -0.044885  -0.044885\n",
       "10 -0.076816 -0.084092 -0.052327  -0.052327\n",
       "11 -0.216567 -0.187606 -0.214062  -0.214062\n",
       "12  0.211234  0.204352  0.219540   0.219540\n",
       "13 -0.047961 -0.053749 -0.036531  -0.036531\n",
       "14 -0.074849 -0.068122 -0.054252  -0.054252\n",
       "15 -0.148102 -0.142878 -0.170216  -0.170216\n",
       "16 -0.052676 -0.052144  0.021666   0.021666\n",
       "17 -0.003426  0.003679 -0.001432  -0.001432"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_covar = pd.DataFrame()\n",
    "df_compare_covar[\"skgmm\"] = skgmm.covariances_[IDX][0]\n",
    "df_compare_covar[\"numpy\"] = covar[IDX][0]\n",
    "df_compare_covar[\"torch\"] = trained_model.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar[\"lightning\"] = gmm_lightning_module.gmm_module.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.639912</td>\n",
       "      <td>3.845917</td>\n",
       "      <td>3.589172</td>\n",
       "      <td>3.589172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.479631</td>\n",
       "      <td>2.352261</td>\n",
       "      <td>2.467333</td>\n",
       "      <td>2.467333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.041528</td>\n",
       "      <td>3.508878</td>\n",
       "      <td>2.368087</td>\n",
       "      <td>2.368087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.246541</td>\n",
       "      <td>-1.232897</td>\n",
       "      <td>-1.053467</td>\n",
       "      <td>-1.053467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.704551</td>\n",
       "      <td>-2.702441</td>\n",
       "      <td>-2.776443</td>\n",
       "      <td>-2.776443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.834039</td>\n",
       "      <td>-4.068906</td>\n",
       "      <td>-4.021445</td>\n",
       "      <td>-4.021445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.075886</td>\n",
       "      <td>3.824865</td>\n",
       "      <td>3.385015</td>\n",
       "      <td>3.385015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.186112</td>\n",
       "      <td>12.503750</td>\n",
       "      <td>12.140152</td>\n",
       "      <td>12.140152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.430341</td>\n",
       "      <td>1.813504</td>\n",
       "      <td>0.944585</td>\n",
       "      <td>0.944585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.943625</td>\n",
       "      <td>-6.014369</td>\n",
       "      <td>-4.569670</td>\n",
       "      <td>-4.569670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.583486</td>\n",
       "      <td>2.718797</td>\n",
       "      <td>2.446911</td>\n",
       "      <td>2.446911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.783519</td>\n",
       "      <td>6.508054</td>\n",
       "      <td>2.710914</td>\n",
       "      <td>2.710914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.711893</td>\n",
       "      <td>-5.512752</td>\n",
       "      <td>-6.137254</td>\n",
       "      <td>-6.137254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-7.107340</td>\n",
       "      <td>-4.249424</td>\n",
       "      <td>-2.948844</td>\n",
       "      <td>-2.948844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6.515602</td>\n",
       "      <td>4.478132</td>\n",
       "      <td>4.733010</td>\n",
       "      <td>4.733010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.886518</td>\n",
       "      <td>3.788214</td>\n",
       "      <td>4.529488</td>\n",
       "      <td>4.529488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1.620808</td>\n",
       "      <td>2.349999</td>\n",
       "      <td>1.487495</td>\n",
       "      <td>1.487495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8.139718</td>\n",
       "      <td>4.800162</td>\n",
       "      <td>4.226908</td>\n",
       "      <td>4.226908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        skgmm      numpy      torch  lightning\n",
       "0    3.639912   3.845917   3.589172   3.589172\n",
       "1    2.479631   2.352261   2.467333   2.467333\n",
       "2    3.041528   3.508878   2.368087   2.368087\n",
       "3   -1.246541  -1.232897  -1.053467  -1.053467\n",
       "4   -2.704551  -2.702441  -2.776443  -2.776443\n",
       "5   -5.834039  -4.068906  -4.021445  -4.021445\n",
       "6    3.075886   3.824865   3.385015   3.385015\n",
       "7   12.186112  12.503750  12.140152  12.140152\n",
       "8    0.430341   1.813504   0.944585   0.944585\n",
       "9   -5.943625  -6.014369  -4.569670  -4.569670\n",
       "10   3.583486   2.718797   2.446911   2.446911\n",
       "11   5.783519   6.508054   2.710914   2.710914\n",
       "12  -5.711893  -5.512752  -6.137254  -6.137254\n",
       "13  -7.107340  -4.249424  -2.948844  -2.948844\n",
       "14   6.515602   4.478132   4.733010   4.733010\n",
       "15   5.886518   3.788214   4.529488   4.529488\n",
       "16   1.620808   2.349999   1.487495   1.487495\n",
       "17   8.139718   4.800162   4.226908   4.226908"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_pre_chol = pd.DataFrame()\n",
    "df_compare_pre_chol[\"skgmm\"] = skgmm.precisions_cholesky_[IDX][0]\n",
    "df_compare_pre_chol[\"numpy\"] = prec_chol[IDX][0]\n",
    "df_compare_pre_chol[\"torch\"] = trained_model.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol[\"lightning\"] = gmm_lightning_module.gmm_module.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004700</td>\n",
       "      <td>0.004545</td>\n",
       "      <td>0.004363</td>\n",
       "      <td>0.004363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029844</td>\n",
       "      <td>0.041581</td>\n",
       "      <td>0.032934</td>\n",
       "      <td>0.032934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021606</td>\n",
       "      <td>0.022298</td>\n",
       "      <td>0.019733</td>\n",
       "      <td>0.019733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002576</td>\n",
       "      <td>0.002501</td>\n",
       "      <td>0.002617</td>\n",
       "      <td>0.002617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006069</td>\n",
       "      <td>0.005619</td>\n",
       "      <td>0.006260</td>\n",
       "      <td>0.006260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004960</td>\n",
       "      <td>0.005710</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.005611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      skgmm     numpy     torch  lightning\n",
       "0  0.004700  0.004545  0.004363   0.004363\n",
       "1  0.000160  0.000160  0.000160   0.000160\n",
       "2  0.029844  0.041581  0.032934   0.032934\n",
       "3  0.021606  0.022298  0.019733   0.019733\n",
       "4  0.002576  0.002501  0.002617   0.002617\n",
       "5  0.000160  0.000160  0.000160   0.000160\n",
       "6  0.006069  0.005619  0.006260   0.006260\n",
       "7  0.004960  0.005710  0.005611   0.005611\n",
       "8  0.000600  0.000600  0.000600   0.000600\n",
       "9  0.000480  0.000480  0.000480   0.000480"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_weights = pd.DataFrame()\n",
    "df_compare_weights[\"skgmm\"] = skgmm.weights_[:10]\n",
    "df_compare_weights[\"numpy\"] = weights[:10]\n",
    "df_compare_weights[\"torch\"] = trained_model.weights[:10]\n",
    "df_compare_weights[\"lightning\"] = gmm_lightning_module.gmm_module.weights.detach().numpy()[:10]\n",
    "df_compare_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(means_, covariances_, weights_, n_samples):\n",
    "    rng = np.random.RandomState(RANDOM_STATE)\n",
    "    n_samples_comp = rng.multinomial(n_samples, weights_)\n",
    "\n",
    "    X = np.vstack(\n",
    "            [\n",
    "                rng.multivariate_normal(mean, covariance, int(sample))\n",
    "                for (mean, covariance, sample) in zip(\n",
    "                    means_, covariances_, n_samples_comp\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    y = np.concatenate(\n",
    "        [np.full(sample, j, dtype=int) for j, sample in enumerate(n_samples_comp)]\n",
    "    )\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.06546331, -1.45815873, -0.33128334,  1.29380454,  1.67838391,\n",
       "         0.08892928,  0.15957208,  1.80299064, -0.12120419, -2.49050242,\n",
       "        -0.13582103, -1.17386479, -1.5188634 ,  0.41852592,  2.42205194,\n",
       "        -1.77503955,  2.07498493,  2.61665642]),\n",
       " 0)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm_samples = sample(skgmm.means_, skgmm.covariances_, skgmm.weights_, n_samples = N_SAMPLES)\n",
    "\n",
    "skgmm_X, skgmm_y = skgmm_samples\n",
    "skgmm_X[IDX], skgmm_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01900764, -1.16245489, -0.77577511,  2.14979001,  2.07757197,\n",
       "         0.07693889, -0.28857952,  2.92392678, -0.0494064 , -4.05625911,\n",
       "        -0.67460345, -0.67508589, -2.63844236,  0.3934814 ,  3.08956995,\n",
       "        -2.02227899,  6.05678877,  4.13936513]),\n",
       " 0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = sample(means, covar, weights, n_samples = N_SAMPLES)\n",
    "\n",
    "X, y = samples\n",
    "X[IDX], y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2x1gj41j1xb5z153q5m_4rn80000gn/T/ipykernel_99151/1110536824.py:7: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  rng.multivariate_normal(mean, covariance, int(sample))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.03574808, -2.79003573, -0.76025084,  0.82357755, -0.20516164,\n",
       "        -0.03460098, -0.07782398,  3.9214106 , -0.22837557,  0.32822871,\n",
       "         0.69329133, -2.19083986, -2.50094329,  2.28448515,  0.32796495,\n",
       "        -1.06755265, 12.07750982,  3.10206355]),\n",
       " 0)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_samples = sample(trained_model.means.detach().numpy(), trained_model.covariances.detach().numpy(), trained_model.weights.detach().numpy(), n_samples = N_SAMPLES)\n",
    "train_model_X, train_model_y = train_model_samples\n",
    "train_model_X[IDX], train_model_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2x1gj41j1xb5z153q5m_4rn80000gn/T/ipykernel_99151/1110536824.py:7: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  rng.multivariate_normal(mean, covariance, int(sample))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.03574808, -2.79003573, -0.76025084,  0.82357755, -0.20516164,\n",
       "        -0.03460098, -0.07782398,  3.9214106 , -0.22837557,  0.32822871,\n",
       "         0.69329133, -2.19083986, -2.50094329,  2.28448515,  0.32796495,\n",
       "        -1.06755265, 12.07750982,  3.10206355]),\n",
       " 0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_samples = sample(gmm_lightning_module.gmm_module.means.detach().numpy(), gmm_lightning_module.gmm_module.covariances.detach().numpy(), gmm_lightning_module.gmm_module.weights.detach().numpy(), n_samples = N_SAMPLES)\n",
    "gmm_lightning_X, gmm_lightning_y = train_model_samples\n",
    "gmm_lightning_X[IDX], gmm_lightning_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSynth-BNsxhSIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
