{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_data = pd.read_csv(\"../../data/processed/historical/train/lcl_data.csv\")\n",
    "df_100K = full_data.sample(100000, random_state=0)\n",
    "df_100K.to_csv(\"../../data/processed/historical/train/lcl_data_100K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "RANDOM_STATE = 0\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(RANDOM_STATE)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from opensynth.data_modules.lcl_data_module import LCLDataModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = Path(\"../../data/processed/historical/train/lcl_data_100K.csv\")\n",
    "stats_path = Path(\"../../data/processed/historical/train/mean_std.csv\")\n",
    "outlier_path = Path(\"../../data/processed/historical/train/outliers.csv\")\n",
    "\n",
    "dm = LCLDataModule(data_path=data_path, stats_path=stats_path, batch_size=25000, n_samples=100000)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaradayVAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder_layers): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=32, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (latent): Linear(in_features=18, out_features=16, bias=True)\n",
       "    (latent_activations): GELU(approximate='none')\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=512, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (reparametriser): ReparametrisationModule(\n",
       "    (mean): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from opensynth.models.faraday import FaradayVAE\n",
    "vae_model = torch.load(\"vae_model.pt\")\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensynth.models.faraday.gaussian_mixture.prepare_gmm_input import encode_data_for_gmm\n",
    "\n",
    "next_batch = next(iter(dm.train_dataloader()))\n",
    "input_tensor = encode_data_for_gmm(data=next_batch, vae_module=vae_model)\n",
    "input_data = input_tensor.detach().numpy()\n",
    "n_samples = len(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 250\n",
    "REG_COVAR = 1e-4\n",
    "EPOCHS = 25\n",
    "IDX = 0\n",
    "CONVERGENCE_TOL = 1e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.4973, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm import gmm_utils\n",
    "\n",
    "labels_, means_, responsibilities_ = gmm_utils.initialise_centroids(\n",
    "        X=input_data, n_components=N_COMPONENTS\n",
    "    )\n",
    "print(labels_.dtype, responsibilities_.dtype, means_.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(5.3050)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "print(gmm_init_params[\"precision_cholesky\"][IDX][0][0])\n",
    "print(gmm_init_params[\"weights\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 5.304963111877441. Initial mean: -0.03158539533615112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:00<00:13,  1.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:01<00:15,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.5084905624389648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:02<00:16,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.23039257526397705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:02<00:15,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.150634765625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:03<00:12,  1.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.12414610385894775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [00:03<00:10,  1.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.11708420515060425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [00:04<00:08,  2.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.09850257635116577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [00:04<00:07,  2.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.07204777002334595\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [00:04<00:06,  2.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.051428377628326416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [00:04<00:05,  2.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.03997069597244263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [00:05<00:04,  2.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.033895134925842285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [00:05<00:04,  2.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.029591619968414307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [00:05<00:04,  2.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.02564871311187744\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [00:06<00:04,  2.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.02242940664291382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [00:06<00:03,  2.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.01864105463027954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [00:07<00:03,  2.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.016461819410324097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [00:07<00:03,  2.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.01425313949584961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [00:08<00:02,  2.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.011691153049468994\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [00:08<00:02,  2.55it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.010412514209747314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [00:08<00:02,  2.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.009731918573379517\n",
      "Converged: True. Number of iterations: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params, training_loop\n",
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureModel\n",
    "\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "\n",
    "means = gmm_init_params[\"means\"].detach().numpy()\n",
    "weights = gmm_init_params[\"weights\"].detach().numpy()\n",
    "prec_chol = gmm_init_params[\"precision_cholesky\"].detach().numpy()\n",
    "print(f\"Initial prec chol: {prec_chol[IDX][0][0]}. Initial mean: {means[IDX][0]}\")\n",
    "\n",
    "torch_gmm = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "torch_gmm.initialise(gmm_init_params)\n",
    "trained_model = training_loop(model=torch_gmm, data=input_tensor, max_iter=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from scipy import linalg\n",
    "\n",
    "def is_symmetric_positive_definite(covariance):\n",
    "    is_symmetric = np.all([np.allclose(covariance[i], covariance[i].T) for i in range(covariance.shape[0])])\n",
    "    is_positive_definite = np.all([np.all(np.linalg.eigvalsh(covariance[i]) > 0.0) for i in range(covariance.shape[0])])\n",
    "    return is_symmetric and is_positive_definite\n",
    "\n",
    "def _estimate_gaussian_parameters(X, resp, reg_covar=REG_COVAR):\n",
    "    nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "    n_components, n_features = means.shape\n",
    "    covariances = np.empty((n_components, n_features, n_features))\n",
    "    for k in range(n_components):\n",
    "        diff = X - means[k]\n",
    "        covariances[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]\n",
    "        covariances[k].flat[:: n_features + 1] += reg_covar\n",
    "\n",
    "    check_covariances = is_symmetric_positive_definite(covariances)\n",
    "    if not check_covariances:\n",
    "        raise ValueError(\"Covariance matrix is not positive definite.\")\n",
    "    return nk, means, covariances\n",
    "\n",
    "def _compute_precision_cholesky(covariances):\n",
    "    estimate_precision_error_message = (\n",
    "        \"Fitting the mixture model failed because some components have \"\n",
    "        \"ill-defined empirical covariance (for instance caused by singleton \"\n",
    "        \"or collapsed samples). Try to decrease the number of components, \"\n",
    "        \"or increase reg_covar.\"\n",
    "    )\n",
    "\n",
    "    n_components, n_features, _ = covariances.shape\n",
    "    precisions_chol = np.empty((n_components, n_features, n_features))\n",
    "    for k, covariance in enumerate(covariances):\n",
    "        try:\n",
    "            cov_chol = linalg.cholesky(covariance, lower=True)\n",
    "        except linalg.LinAlgError:\n",
    "            raise ValueError(estimate_precision_error_message)\n",
    "        precisions_chol[k] = linalg.solve_triangular(\n",
    "            cov_chol, np.eye(n_features), lower=True\n",
    "        ).T\n",
    "    return precisions_chol\n",
    "\n",
    "def _compute_log_det_cholesky(matrix_chol, n_features):\n",
    "    n_components, _, _ = matrix_chol.shape\n",
    "    log_det_chol = np.sum(\n",
    "        np.log(matrix_chol.reshape(n_components, -1)[:, :: n_features + 1]), 1\n",
    "    )\n",
    "    return log_det_chol\n",
    "\n",
    "def _estimate_log_gaussian_prob(X, means, precisions_chol):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_components, _ = means.shape\n",
    "\n",
    "    log_det = _compute_log_det_cholesky(precisions_chol, n_features)\n",
    "\n",
    "    log_prob = np.empty((n_samples, n_components))\n",
    "    for k, (mu, prec_chol) in enumerate(zip(means, precisions_chol)):\n",
    "        y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n",
    "        log_prob[:, k] = np.sum(np.square(y), axis=1)\n",
    "    return -0.5 * (n_features * np.log(2 * np.pi) + log_prob) + log_det\n",
    "\n",
    "def _estimate_log_weights(weights):\n",
    "        return np.log(weights)\n",
    "\n",
    "def _estimate_weighted_log_prob(X, means, precisions_chol, weights):\n",
    "        return _estimate_log_gaussian_prob(X, means, precisions_chol) + _estimate_log_weights(weights)\n",
    "\n",
    "\n",
    "def _estimate_log_prob_resp(X, means, precisions_chol, weights):\n",
    "    weighted_log_prob = _estimate_weighted_log_prob(X, means, precisions_chol, weights)\n",
    "    log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
    "    with np.errstate(under=\"ignore\"):\n",
    "        log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]\n",
    "    return log_prob_norm, log_resp\n",
    "\n",
    "def _e_step(X,means, precisions_chol, weights):\n",
    "    log_prob_norm, log_resp = _estimate_log_prob_resp(X, means, precisions_chol, weights)\n",
    "    return np.mean(log_prob_norm), log_resp\n",
    "\n",
    "def _m_step(X, log_reponsibilities, reg_covar=REG_COVAR):\n",
    "\n",
    "    weights_, means_, covariances_ = _estimate_gaussian_parameters(X,np.exp(log_reponsibilities),reg_covar=reg_covar)\n",
    "    weights_ /= weights_.sum()\n",
    "\n",
    "    precision_cholesky_ = _compute_precision_cholesky(covariances=covariances_)\n",
    "\n",
    "    return precision_cholesky_, weights_, means_, covariances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 5.304963111877441. Initial mean: -0.03158539533615112\n",
      "Old Prec Chol: 5.304963111877441. Old means: -0.03158539533615112\n",
      "New prec chol: 5.354319690242408. New means: -0.0666737731178448\n",
      "Change: inf\n",
      "Old Prec Chol: 5.354319690242408. Old means: -0.0666737731178448\n",
      "New prec chol: 5.425739612214089. New means: -0.07675008384865534\n",
      "Change: 0.5081508811522741\n",
      "Old Prec Chol: 5.425739612214089. Old means: -0.07675008384865534\n",
      "New prec chol: 5.431166511078023. New means: -0.07761530600745582\n",
      "Change: 0.23028293837190317\n",
      "Old Prec Chol: 5.431166511078023. Old means: -0.07761530600745582\n",
      "New prec chol: 5.447434660478251. New means: -0.0726697539764158\n",
      "Change: 0.15055546759907723\n",
      "Old Prec Chol: 5.447434660478251. Old means: -0.0726697539764158\n",
      "New prec chol: 5.481500604338222. New means: -0.06364515597704859\n",
      "Change: 0.12406301869742964\n",
      "Old Prec Chol: 5.481500604338222. Old means: -0.06364515597704859\n",
      "New prec chol: 5.535471568901376. New means: -0.05242268744966199\n",
      "Change: 0.11701916756599628\n",
      "Old Prec Chol: 5.535471568901376. Old means: -0.05242268744966199\n",
      "New prec chol: 5.620235304411401. New means: -0.04071260422289683\n",
      "Change: 0.09842041405708857\n",
      "Old Prec Chol: 5.620235304411401. Old means: -0.04071260422289683\n",
      "New prec chol: 5.734015249011019. New means: -0.0297947389607096\n",
      "Change: 0.0719978843143273\n",
      "Old Prec Chol: 5.734015249011019. Old means: -0.0297947389607096\n",
      "New prec chol: 5.873733260572322. New means: -0.020402754928139234\n",
      "Change: 0.05140268118556457\n",
      "Old Prec Chol: 5.873733260572322. Old means: -0.020402754928139234\n",
      "New prec chol: 6.022278979611449. New means: -0.01311995879753984\n",
      "Change: 0.03998599135987646\n",
      "Old Prec Chol: 6.022278979611449. Old means: -0.01311995879753984\n",
      "New prec chol: 6.154924968711363. New means: -0.008544173187010732\n",
      "Change: 0.033891266462902414\n",
      "Old Prec Chol: 6.154924968711363. Old means: -0.008544173187010732\n",
      "New prec chol: 6.251948956415033. New means: -0.006184652369997113\n",
      "Change: 0.02958811394767724\n",
      "Old Prec Chol: 6.251948956415033. Old means: -0.006184652369997113\n",
      "New prec chol: 6.313752115682206. New means: -0.004954417011561708\n",
      "Change: 0.0256597840560695\n",
      "Old Prec Chol: 6.313752115682206. Old means: -0.004954417011561708\n",
      "New prec chol: 6.351341201591378. New means: -0.0043448711736738185\n",
      "Change: 0.02248824430468721\n",
      "Old Prec Chol: 6.351341201591378. Old means: -0.0043448711736738185\n",
      "New prec chol: 6.374425243516772. New means: -0.004139049813677528\n",
      "Change: 0.018648067694882697\n",
      "Old Prec Chol: 6.374425243516772. Old means: -0.004139049813677528\n",
      "New prec chol: 6.3978656444314375. New means: -0.004047949027092119\n",
      "Change: 0.016423520259365054\n",
      "Old Prec Chol: 6.3978656444314375. Old means: -0.004047949027092119\n",
      "New prec chol: 6.430989593224513. New means: -0.003831842509813524\n",
      "Change: 0.014247953364737553\n",
      "Old Prec Chol: 6.430989593224513. Old means: -0.003831842509813524\n",
      "New prec chol: 6.468796162028299. New means: -0.0034971642195516664\n",
      "Change: 0.01183848973392343\n",
      "Old Prec Chol: 6.468796162028299. Old means: -0.0034971642195516664\n",
      "New prec chol: 6.509287385911478. New means: -0.0030951872792849954\n",
      "Change: 0.010345062154678564\n",
      "Old Prec Chol: 6.509287385911478. Old means: -0.0030951872792849954\n",
      "New prec chol: 6.551072174427893. New means: -0.002572419270616087\n",
      "Change: 0.009775308401456018\n",
      "Converged: True. Number of iterations: 19\n"
     ]
    }
   ],
   "source": [
    "means = gmm_init_params[\"means\"].detach().numpy()\n",
    "weights = gmm_init_params[\"weights\"].detach().numpy()\n",
    "prec_chol = gmm_init_params[\"precision_cholesky\"].detach().numpy()\n",
    "\n",
    "print(f\"Initial prec chol: {prec_chol[IDX][0][0]}. Initial mean: {means[IDX][0]}\")\n",
    "\n",
    "converged = False\n",
    "lower_bound = -np.inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    prev_lower_bound = lower_bound\n",
    "\n",
    "    print(f\"Old Prec Chol: {prec_chol[IDX][0][0]}. Old means: {means[IDX][0]}\")\n",
    "    log_prob, log_resp = _e_step(input_data, means, prec_chol, weights)\n",
    "    prec_chol, weights, means, covar = _m_step(input_data, log_resp)\n",
    "\n",
    "    print(f\"New prec chol: {prec_chol[IDX][0][0]}. New means: {means[IDX][0]}\")\n",
    "\n",
    "    # Converegence\n",
    "    lower_bound = log_prob\n",
    "    change = abs(lower_bound - prev_lower_bound)\n",
    "    print(f\"Change: {change}\")\n",
    "    if change < CONVERGENCE_TOL:\n",
    "        converged = True\n",
    "        break\n",
    "\n",
    "print(f'Converged: {converged}. Number of iterations: {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 1\t time lapse 7.33542s\t ll change inf\n",
      "  Iteration 2\t time lapse 3.47101s\t ll change 0.51692\n",
      "  Iteration 3\t time lapse 3.50806s\t ll change 0.23751\n",
      "  Iteration 4\t time lapse 3.10982s\t ll change 0.15756\n",
      "  Iteration 5\t time lapse 2.86738s\t ll change 0.12937\n",
      "  Iteration 6\t time lapse 3.63363s\t ll change 0.12114\n",
      "  Iteration 7\t time lapse 3.53204s\t ll change 0.10132\n",
      "  Iteration 8\t time lapse 2.65495s\t ll change 0.07272\n",
      "  Iteration 9\t time lapse 2.38858s\t ll change 0.05265\n",
      "  Iteration 10\t time lapse 2.66181s\t ll change 0.04181\n",
      "  Iteration 11\t time lapse 2.27012s\t ll change 0.03483\n",
      "  Iteration 12\t time lapse 2.43596s\t ll change 0.03022\n",
      "  Iteration 13\t time lapse 2.35215s\t ll change 0.02537\n",
      "  Iteration 14\t time lapse 2.29618s\t ll change 0.02154\n",
      "  Iteration 15\t time lapse 2.25619s\t ll change 0.01948\n",
      "  Iteration 16\t time lapse 2.35089s\t ll change 0.01818\n",
      "  Iteration 17\t time lapse 2.31402s\t ll change 0.01645\n",
      "  Iteration 18\t time lapse 2.36858s\t ll change 0.01466\n",
      "  Iteration 19\t time lapse 2.37028s\t ll change 0.01303\n",
      "  Iteration 20\t time lapse 2.19514s\t ll change 0.01193\n",
      "  Iteration 21\t time lapse 2.16888s\t ll change 0.01127\n",
      "  Iteration 22\t time lapse 2.40006s\t ll change 0.01038\n",
      "  Iteration 23\t time lapse 2.17835s\t ll change 0.01002\n",
      "  Iteration 24\t time lapse 2.24588s\t ll change 0.00932\n",
      "Initialization converged. time lapse 67.36547s\t lower bound 0.12104.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "init_weights = gmm_init_params[\"weights\"]\n",
    "init_means = gmm_init_params[\"means\"]\n",
    "\n",
    "skgmm = GaussianMixture(n_components=N_COMPONENTS, covariance_type='full', tol=CONVERGENCE_TOL, max_iter=EPOCHS, random_state=0, means_init = init_means, weights_init=init_weights, verbose=2, verbose_interval=1)\n",
    "skgmm.fit(input_data)\n",
    "skgmm_pred = skgmm.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 24)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm.converged_, skgmm.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_tensor: torch.Tensor):\n",
    "        self.data = data_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "class CustomDataModule(LightningDataModule):\n",
    "    def __init__(self, data_tensor: torch.Tensor, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.data_tensor = data_tensor\n",
    "        self.batch_size = batch_size\n",
    "    def setup(self, stage=\"\"):\n",
    "        self.custom_ds = CustomDataset(self.data_tensor)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.custom_ds, batch_size=self.batch_size, shuffle=False, generator=g, worker_init_fn=seed_worker)\n",
    "    \n",
    "custom_dm = CustomDataModule(data_tensor=input_tensor, batch_size=25000)\n",
    "custom_dm.setup(stage=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.4973, grad_fn=<SelectBackward0>)\n",
      "tensor(0.4973, grad_fn=<SelectBackward0>)\n",
      "tensor(0.4973, grad_fn=<SelectBackward0>)\n",
      "tensor(0.4973, grad_fn=<SelectBackward0>)\n",
      "tensor(0.4973, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(next(iter(custom_dm.train_dataloader()))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 5.304963111877441. Initial mean: -0.03158539533615112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name                      | Type                    | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | gmm_module                | GaussianMixtureModel    | 0      | train\n",
      "1 | vae_module                | FaradayVAE              | 402 K  | eval \n",
      "2 | weight_metric             | WeightsMetric           | 0      | train\n",
      "3 | mean_metric               | MeansMetric             | 0      | train\n",
      "4 | precision_cholesky_metric | PrecisionCholeskyMetric | 0      | train\n",
      "5 | covariance_metric         | CovarianceMetric        | 0      | train\n",
      "6 | log_prob                  | LogProbMetric           | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "402 K     Trainable params\n",
      "0         Non-trainable params\n",
      "402 K     Total params\n",
      "1.609     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "32        Modules in eval mode\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s, v_num=39]Local weights at rank: 0 - means: 0.0149, -0.0667\n",
      "Reduced weights, means: 0.0149, -0.0667\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s, v_num=39]Local weights at rank: 0 - means: 0.0174, -0.0768\n",
      "Reduced weights, means: 0.0174, -0.0768\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=39]Local weights at rank: 0 - means: 0.0194, -0.0776\n",
      "Reduced weights, means: 0.0194, -0.0776\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=39]Local weights at rank: 0 - means: 0.0209, -0.0727\n",
      "Reduced weights, means: 0.0209, -0.0727\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  2.15it/s, v_num=39]Local weights at rank: 0 - means: 0.0222, -0.0637\n",
      "Reduced weights, means: 0.0222, -0.0637\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=39]Local weights at rank: 0 - means: 0.0232, -0.0525\n",
      "Reduced weights, means: 0.0232, -0.0525\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=39]Local weights at rank: 0 - means: 0.0241, -0.0408\n",
      "Reduced weights, means: 0.0241, -0.0408\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s, v_num=39]Local weights at rank: 0 - means: 0.0250, -0.0300\n",
      "Reduced weights, means: 0.0250, -0.0300\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  2.45it/s, v_num=39]Local weights at rank: 0 - means: 0.0260, -0.0207\n",
      "Reduced weights, means: 0.0260, -0.0207\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.32it/s, v_num=39]Local weights at rank: 0 - means: 0.0272, -0.0135\n",
      "Reduced weights, means: 0.0272, -0.0135\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s, v_num=39]Local weights at rank: 0 - means: 0.0283, -0.0091\n",
      "Reduced weights, means: 0.0283, -0.0091\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, v_num=39]Local weights at rank: 0 - means: 0.0293, -0.0068\n",
      "Reduced weights, means: 0.0293, -0.0068\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, v_num=39]Local weights at rank: 0 - means: 0.0300, -0.0057\n",
      "Reduced weights, means: 0.0300, -0.0057\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=39]Local weights at rank: 0 - means: 0.0304, -0.0051\n",
      "Reduced weights, means: 0.0304, -0.0051\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=39]Local weights at rank: 0 - means: 0.0307, -0.0050\n",
      "Reduced weights, means: 0.0307, -0.0050\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  2.22it/s, v_num=39]Local weights at rank: 0 - means: 0.0308, -0.0050\n",
      "Reduced weights, means: 0.0308, -0.0050\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=39]Local weights at rank: 0 - means: 0.0307, -0.0048\n",
      "Reduced weights, means: 0.0307, -0.0048\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s, v_num=39]Local weights at rank: 0 - means: 0.0306, -0.0045\n",
      "Reduced weights, means: 0.0306, -0.0045\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=39]Local weights at rank: 0 - means: 0.0305, -0.0042\n",
      "Reduced weights, means: 0.0305, -0.0042\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, v_num=39]Local weights at rank: 0 - means: 0.0303, -0.0037\n",
      "Reduced weights, means: 0.0303, -0.0037\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.38it/s, v_num=39]\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureLightningModule\n",
    "gmm_module = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "gmm_module.initialise(gmm_init_params)\n",
    "print(f\"Initial prec chol: {gmm_module.precision_cholesky[IDX][0][0]}. Initial mean: {gmm_module.means[IDX][0]}\")\n",
    "\n",
    "gmm_lightning_module = GaussianMixtureLightningModule(\n",
    "    gmm_module = gmm_module,\n",
    "    vae_module = vae_model,\n",
    "    num_components = gmm_module.num_components,\n",
    "    num_features = gmm_module.num_features,\n",
    "    reg_covar = gmm_module.reg_covar,\n",
    "    convergence_tolerance = CONVERGENCE_TOL,\n",
    "    compute_on_batch=True\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=EPOCHS, accelerator=\"cpu\", deterministic=True )\n",
    "trainer.fit(gmm_lightning_module, custom_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "\n",
      "  | Name                      | Type                    | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | gmm_module                | GaussianMixtureModel    | 0      | train\n",
      "1 | vae_module                | FaradayVAE              | 402 K  | eval \n",
      "2 | weight_metric             | WeightsMetric           | 0      | train\n",
      "3 | mean_metric               | MeansMetric             | 0      | train\n",
      "4 | precision_cholesky_metric | PrecisionCholeskyMetric | 0      | train\n",
      "5 | covariance_metric         | CovarianceMetric        | 0      | train\n",
      "6 | log_prob                  | LogProbMetric           | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "402 K     Trainable params\n",
      "0         Non-trainable params\n",
      "402 K     Total params\n",
      "1.609     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "32        Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 5.304963111877441. Initial mean: -0.03158539533615112\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  2.53it/s, v_num=40]Local weights at rank: 0 - means: 0.0149, -0.0667\n",
      "Reduced weights, means: 0.0149, -0.0667\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s, v_num=40]Local weights at rank: 0 - means: 0.0174, -0.0768\n",
      "Reduced weights, means: 0.0174, -0.0768\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  2.60it/s, v_num=40]Local weights at rank: 0 - means: 0.0194, -0.0776\n",
      "Reduced weights, means: 0.0194, -0.0776\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=40]Local weights at rank: 0 - means: 0.0209, -0.0727\n",
      "Reduced weights, means: 0.0209, -0.0727\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  2.18it/s, v_num=40]Local weights at rank: 0 - means: 0.0222, -0.0637\n",
      "Reduced weights, means: 0.0222, -0.0637\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  2.01it/s, v_num=40]Local weights at rank: 0 - means: 0.0232, -0.0525\n",
      "Reduced weights, means: 0.0232, -0.0525\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=40]Local weights at rank: 0 - means: 0.0241, -0.0408\n",
      "Reduced weights, means: 0.0241, -0.0408\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s, v_num=40]Local weights at rank: 0 - means: 0.0250, -0.0300\n",
      "Reduced weights, means: 0.0250, -0.0300\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  2.42it/s, v_num=40]Local weights at rank: 0 - means: 0.0260, -0.0207\n",
      "Reduced weights, means: 0.0260, -0.0207\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=40]Local weights at rank: 0 - means: 0.0272, -0.0135\n",
      "Reduced weights, means: 0.0272, -0.0135\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  2.14it/s, v_num=40]Local weights at rank: 0 - means: 0.0283, -0.0091\n",
      "Reduced weights, means: 0.0283, -0.0091\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  2.50it/s, v_num=40]Local weights at rank: 0 - means: 0.0293, -0.0068\n",
      "Reduced weights, means: 0.0293, -0.0068\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  2.30it/s, v_num=40]Local weights at rank: 0 - means: 0.0300, -0.0057\n",
      "Reduced weights, means: 0.0300, -0.0057\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=40]Local weights at rank: 0 - means: 0.0304, -0.0051\n",
      "Reduced weights, means: 0.0304, -0.0051\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  2.64it/s, v_num=40]Local weights at rank: 0 - means: 0.0307, -0.0050\n",
      "Reduced weights, means: 0.0307, -0.0050\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  1.87it/s, v_num=40]Local weights at rank: 0 - means: 0.0308, -0.0050\n",
      "Reduced weights, means: 0.0308, -0.0050\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  1.92it/s, v_num=40]Local weights at rank: 0 - means: 0.0307, -0.0048\n",
      "Reduced weights, means: 0.0307, -0.0048\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  2.28it/s, v_num=40]Local weights at rank: 0 - means: 0.0306, -0.0045\n",
      "Reduced weights, means: 0.0306, -0.0045\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s, v_num=40]Local weights at rank: 0 - means: 0.0305, -0.0042\n",
      "Reduced weights, means: 0.0305, -0.0042\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s, v_num=40]Local weights at rank: 0 - means: 0.0303, -0.0037\n",
      "Reduced weights, means: 0.0303, -0.0037\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=40]\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureLightningModule, GaussianMixtureModel\n",
    "gmm_module = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "gmm_module.initialise(gmm_init_params)\n",
    "print(f\"Initial prec chol: {gmm_module.precision_cholesky[IDX][0][0]}. Initial mean: {gmm_module.means[IDX][0]}\")\n",
    "\n",
    "gmm_lightning_module = GaussianMixtureLightningModule(\n",
    "    gmm_module = gmm_module,\n",
    "    vae_module = vae_model,\n",
    "    num_components = gmm_module.num_components,\n",
    "    num_features = gmm_module.num_features,\n",
    "    reg_covar = gmm_module.reg_covar,\n",
    "    convergence_tolerance = CONVERGENCE_TOL,\n",
    "    compute_on_batch=False\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=EPOCHS, accelerator=\"cpu\", deterministic=True )\n",
    "trainer.fit(gmm_lightning_module, custom_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0303), tensor(-0.0037))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_module.gmm_module.weights[0], gmm_lightning_module.gmm_module.means[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0303), tensor(-0.0037))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_module.weight_metric.compute()[0], gmm_lightning_module.mean_metric.compute()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.049669</td>\n",
       "      <td>-0.002572</td>\n",
       "      <td>-0.003688</td>\n",
       "      <td>-0.003688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-2.707486</td>\n",
       "      <td>-2.928096</td>\n",
       "      <td>-2.921445</td>\n",
       "      <td>-2.921445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.303743</td>\n",
       "      <td>0.182399</td>\n",
       "      <td>0.184473</td>\n",
       "      <td>0.184473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.109831</td>\n",
       "      <td>0.073859</td>\n",
       "      <td>0.069771</td>\n",
       "      <td>0.069771</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.012985</td>\n",
       "      <td>0.100071</td>\n",
       "      <td>0.096574</td>\n",
       "      <td>0.096574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.090285</td>\n",
       "      <td>0.095880</td>\n",
       "      <td>0.095612</td>\n",
       "      <td>0.095612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.532626</td>\n",
       "      <td>0.414696</td>\n",
       "      <td>0.416915</td>\n",
       "      <td>0.416915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.637247</td>\n",
       "      <td>1.820193</td>\n",
       "      <td>1.817437</td>\n",
       "      <td>1.817437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.010636</td>\n",
       "      <td>-0.035010</td>\n",
       "      <td>-0.034580</td>\n",
       "      <td>-0.034580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.646689</td>\n",
       "      <td>-1.858131</td>\n",
       "      <td>-1.849922</td>\n",
       "      <td>-1.849922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.697293</td>\n",
       "      <td>0.627190</td>\n",
       "      <td>0.628446</td>\n",
       "      <td>0.628446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.083588</td>\n",
       "      <td>-0.082038</td>\n",
       "      <td>-0.079670</td>\n",
       "      <td>-0.079670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.325839</td>\n",
       "      <td>0.272189</td>\n",
       "      <td>0.270991</td>\n",
       "      <td>0.270991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.726988</td>\n",
       "      <td>0.787408</td>\n",
       "      <td>0.787077</td>\n",
       "      <td>0.787077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.233333</td>\n",
       "      <td>1.325930</td>\n",
       "      <td>1.321312</td>\n",
       "      <td>1.321312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.198755</td>\n",
       "      <td>-2.365580</td>\n",
       "      <td>-2.359361</td>\n",
       "      <td>-2.359361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.938204</td>\n",
       "      <td>6.913948</td>\n",
       "      <td>6.912699</td>\n",
       "      <td>6.912699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.810847</td>\n",
       "      <td>2.738045</td>\n",
       "      <td>2.739079</td>\n",
       "      <td>2.739079</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0  -0.049669 -0.002572 -0.003688  -0.003688\n",
       "1  -2.707486 -2.928096 -2.921445  -2.921445\n",
       "2   0.303743  0.182399  0.184473   0.184473\n",
       "3  -0.109831  0.073859  0.069771   0.069771\n",
       "4   0.012985  0.100071  0.096574   0.096574\n",
       "5   0.090285  0.095880  0.095612   0.095612\n",
       "6   0.532626  0.414696  0.416915   0.416915\n",
       "7   1.637247  1.820193  1.817437   1.817437\n",
       "8  -0.010636 -0.035010 -0.034580  -0.034580\n",
       "9  -1.646689 -1.858131 -1.849922  -1.849922\n",
       "10  0.697293  0.627190  0.628446   0.628446\n",
       "11  0.083588 -0.082038 -0.079670  -0.079670\n",
       "12  0.325839  0.272189  0.270991   0.270991\n",
       "13  0.726988  0.787408  0.787077   0.787077\n",
       "14  1.233333  1.325930  1.321312   1.321312\n",
       "15 -2.198755 -2.365580 -2.359361  -2.359361\n",
       "16  6.938204  6.913948  6.912699   6.912699\n",
       "17  2.810847  2.738045  2.739079   2.739079"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_means = pd.DataFrame()\n",
    "df_compare_means[\"skgmm\"] = skgmm.means_[IDX]\n",
    "df_compare_means[\"numpy\"] = means[IDX]\n",
    "df_compare_means[\"torch\"] = trained_model.means[IDX]\n",
    "df_compare_means[\"lightning\"] = gmm_lightning_module.gmm_module.means[IDX]\n",
    "df_compare_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.0316, -2.8152,  0.0335,  0.3134,  0.1846,  0.0512,  0.2501,  2.1094,\n",
       "        -0.0596, -2.1234,  0.4170, -0.0876, -0.0460,  0.7939,  1.4049, -2.3318,\n",
       "         4.5358,  1.2399])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_init_params[\"means\"][IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017656</td>\n",
       "      <td>0.023301</td>\n",
       "      <td>0.023192</td>\n",
       "      <td>0.023192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.066879</td>\n",
       "      <td>-0.087802</td>\n",
       "      <td>-0.087399</td>\n",
       "      <td>-0.087399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.020881</td>\n",
       "      <td>-0.023410</td>\n",
       "      <td>-0.023240</td>\n",
       "      <td>-0.023240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.029825</td>\n",
       "      <td>0.038741</td>\n",
       "      <td>0.038555</td>\n",
       "      <td>0.038555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.021761</td>\n",
       "      <td>0.038529</td>\n",
       "      <td>0.038498</td>\n",
       "      <td>0.038498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.007635</td>\n",
       "      <td>0.011312</td>\n",
       "      <td>0.011275</td>\n",
       "      <td>0.011275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.016465</td>\n",
       "      <td>-0.015620</td>\n",
       "      <td>-0.015511</td>\n",
       "      <td>-0.015511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.016911</td>\n",
       "      <td>0.018662</td>\n",
       "      <td>0.018408</td>\n",
       "      <td>0.018408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.003483</td>\n",
       "      <td>-0.003759</td>\n",
       "      <td>-0.003729</td>\n",
       "      <td>-0.003729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.036252</td>\n",
       "      <td>-0.053979</td>\n",
       "      <td>-0.053962</td>\n",
       "      <td>-0.053962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.002098</td>\n",
       "      <td>0.001644</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.001633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.048491</td>\n",
       "      <td>-0.062710</td>\n",
       "      <td>-0.062302</td>\n",
       "      <td>-0.062302</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.015314</td>\n",
       "      <td>0.017880</td>\n",
       "      <td>0.017944</td>\n",
       "      <td>0.017944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.014510</td>\n",
       "      <td>0.019040</td>\n",
       "      <td>0.018825</td>\n",
       "      <td>0.018825</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.020142</td>\n",
       "      <td>0.038426</td>\n",
       "      <td>0.038441</td>\n",
       "      <td>0.038441</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.047407</td>\n",
       "      <td>-0.065697</td>\n",
       "      <td>-0.065515</td>\n",
       "      <td>-0.065515</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.040891</td>\n",
       "      <td>0.033842</td>\n",
       "      <td>0.034912</td>\n",
       "      <td>0.034912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.018379</td>\n",
       "      <td>0.038758</td>\n",
       "      <td>0.038364</td>\n",
       "      <td>0.038364</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0   0.017656  0.023301  0.023192   0.023192\n",
       "1  -0.066879 -0.087802 -0.087399  -0.087399\n",
       "2  -0.020881 -0.023410 -0.023240  -0.023240\n",
       "3   0.029825  0.038741  0.038555   0.038555\n",
       "4   0.021761  0.038529  0.038498   0.038498\n",
       "5   0.007635  0.011312  0.011275   0.011275\n",
       "6  -0.016465 -0.015620 -0.015511  -0.015511\n",
       "7   0.016911  0.018662  0.018408   0.018408\n",
       "8  -0.003483 -0.003759 -0.003729  -0.003729\n",
       "9  -0.036252 -0.053979 -0.053962  -0.053962\n",
       "10 -0.002098  0.001644  0.001633   0.001633\n",
       "11 -0.048491 -0.062710 -0.062302  -0.062302\n",
       "12  0.015314  0.017880  0.017944   0.017944\n",
       "13  0.014510  0.019040  0.018825   0.018825\n",
       "14  0.020142  0.038426  0.038441   0.038441\n",
       "15 -0.047407 -0.065697 -0.065515  -0.065515\n",
       "16  0.040891  0.033842  0.034912   0.034912\n",
       "17  0.018379  0.038758  0.038364   0.038364"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_covar = pd.DataFrame()\n",
    "df_compare_covar[\"skgmm\"] = skgmm.covariances_[IDX][0]\n",
    "df_compare_covar[\"numpy\"] = covar[IDX][0]\n",
    "df_compare_covar[\"torch\"] = trained_model.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar[\"lightning\"] = gmm_lightning_module.gmm_module.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.525883</td>\n",
       "      <td>6.551072</td>\n",
       "      <td>6.566400</td>\n",
       "      <td>6.566400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.392054</td>\n",
       "      <td>5.355093</td>\n",
       "      <td>5.367649</td>\n",
       "      <td>5.367649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.217989</td>\n",
       "      <td>6.399017</td>\n",
       "      <td>6.407043</td>\n",
       "      <td>6.407043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-4.754001</td>\n",
       "      <td>-3.943360</td>\n",
       "      <td>-3.980647</td>\n",
       "      <td>-3.980647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-7.994878</td>\n",
       "      <td>-6.608500</td>\n",
       "      <td>-6.620760</td>\n",
       "      <td>-6.620760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-11.216321</td>\n",
       "      <td>-8.930598</td>\n",
       "      <td>-8.937640</td>\n",
       "      <td>-8.937640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>4.903968</td>\n",
       "      <td>5.665672</td>\n",
       "      <td>5.663373</td>\n",
       "      <td>5.663373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>23.009691</td>\n",
       "      <td>13.939803</td>\n",
       "      <td>13.997698</td>\n",
       "      <td>13.997698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-1.872313</td>\n",
       "      <td>-1.436411</td>\n",
       "      <td>-1.420174</td>\n",
       "      <td>-1.420174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-17.834390</td>\n",
       "      <td>-14.562229</td>\n",
       "      <td>-14.590742</td>\n",
       "      <td>-14.590742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8.223420</td>\n",
       "      <td>4.728659</td>\n",
       "      <td>4.809395</td>\n",
       "      <td>4.809395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11.581919</td>\n",
       "      <td>10.362807</td>\n",
       "      <td>10.370152</td>\n",
       "      <td>10.370152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-3.528971</td>\n",
       "      <td>-0.999375</td>\n",
       "      <td>-0.998038</td>\n",
       "      <td>-0.998038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-9.912942</td>\n",
       "      <td>-4.954043</td>\n",
       "      <td>-5.014349</td>\n",
       "      <td>-5.014349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.209757</td>\n",
       "      <td>1.505791</td>\n",
       "      <td>1.501181</td>\n",
       "      <td>1.501181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-2.718472</td>\n",
       "      <td>-1.603686</td>\n",
       "      <td>-1.615772</td>\n",
       "      <td>-1.615772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-3.557216</td>\n",
       "      <td>-1.072163</td>\n",
       "      <td>-1.044492</td>\n",
       "      <td>-1.044492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-1.656508</td>\n",
       "      <td>-0.681579</td>\n",
       "      <td>-0.686414</td>\n",
       "      <td>-0.686414</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        skgmm      numpy      torch  lightning\n",
       "0    7.525883   6.551072   6.566400   6.566400\n",
       "1    6.392054   5.355093   5.367649   5.367649\n",
       "2    8.217989   6.399017   6.407043   6.407043\n",
       "3   -4.754001  -3.943360  -3.980647  -3.980647\n",
       "4   -7.994878  -6.608500  -6.620760  -6.620760\n",
       "5  -11.216321  -8.930598  -8.937640  -8.937640\n",
       "6    4.903968   5.665672   5.663373   5.663373\n",
       "7   23.009691  13.939803  13.997698  13.997698\n",
       "8   -1.872313  -1.436411  -1.420174  -1.420174\n",
       "9  -17.834390 -14.562229 -14.590742 -14.590742\n",
       "10   8.223420   4.728659   4.809395   4.809395\n",
       "11  11.581919  10.362807  10.370152  10.370152\n",
       "12  -3.528971  -0.999375  -0.998038  -0.998038\n",
       "13  -9.912942  -4.954043  -5.014349  -5.014349\n",
       "14   3.209757   1.505791   1.501181   1.501181\n",
       "15  -2.718472  -1.603686  -1.615772  -1.615772\n",
       "16  -3.557216  -1.072163  -1.044492  -1.044492\n",
       "17  -1.656508  -0.681579  -0.686414  -0.686414"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_pre_chol = pd.DataFrame()\n",
    "df_compare_pre_chol[\"skgmm\"] = skgmm.precisions_cholesky_[IDX][0]\n",
    "df_compare_pre_chol[\"numpy\"] = prec_chol[IDX][0]\n",
    "df_compare_pre_chol[\"torch\"] = trained_model.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol[\"lightning\"] = gmm_lightning_module.gmm_module.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.028506</td>\n",
       "      <td>0.030255</td>\n",
       "      <td>0.030305</td>\n",
       "      <td>0.030305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.000200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004717</td>\n",
       "      <td>0.004476</td>\n",
       "      <td>0.004478</td>\n",
       "      <td>0.004478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.003403</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.003295</td>\n",
       "      <td>0.003295</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013637</td>\n",
       "      <td>0.011810</td>\n",
       "      <td>0.011803</td>\n",
       "      <td>0.011803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000320</td>\n",
       "      <td>0.000320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.002364</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.002256</td>\n",
       "      <td>0.002256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.002725</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.002665</td>\n",
       "      <td>0.002665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000240</td>\n",
       "      <td>0.000240</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      skgmm     numpy     torch  lightning\n",
       "0  0.028506  0.030255  0.030305   0.030305\n",
       "1  0.000200  0.000200  0.000200   0.000200\n",
       "2  0.004717  0.004476  0.004478   0.004478\n",
       "3  0.003403  0.003295  0.003295   0.003295\n",
       "4  0.000600  0.000600  0.000600   0.000600\n",
       "5  0.013637  0.011810  0.011803   0.011803\n",
       "6  0.000320  0.000320  0.000320   0.000320\n",
       "7  0.002364  0.002256  0.002256   0.002256\n",
       "8  0.002725  0.002665  0.002665   0.002665\n",
       "9  0.000240  0.000240  0.000240   0.000240"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_weights = pd.DataFrame()\n",
    "df_compare_weights[\"skgmm\"] = skgmm.weights_[:10]\n",
    "df_compare_weights[\"numpy\"] = weights[:10]\n",
    "df_compare_weights[\"torch\"] = trained_model.weights[:10]\n",
    "df_compare_weights[\"lightning\"] = gmm_lightning_module.gmm_module.weights.detach().numpy()[:10]\n",
    "df_compare_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(means_, covariances_, weights_, n_samples):\n",
    "    rng = np.random.RandomState(RANDOM_STATE)\n",
    "    n_samples_comp = rng.multinomial(n_samples, weights_)\n",
    "    \n",
    "    X = np.vstack(\n",
    "            [\n",
    "                rng.multivariate_normal(mean, covariance, int(sample))\n",
    "                for (mean, covariance, sample) in zip(\n",
    "                    means_, covariances_, n_samples_comp\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    y = np.concatenate(\n",
    "        [np.full(sample, j, dtype=int) for j, sample in enumerate(n_samples_comp)]\n",
    "    )\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_sample(means_, covariances_, weights_, n_samples):\n",
    "    # Set up the random generator with a specified seed\n",
    "    generator = torch.Generator().manual_seed(RANDOM_STATE)\n",
    "    \n",
    "    # Sample component counts from the multinomial distribution\n",
    "    n_samples_comp = torch.multinomial(weights_, n_samples, replacement=True, generator=generator).bincount(minlength=len(weights_))\n",
    "    \n",
    "    # Initialize lists to collect samples and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Sample from each component based on the number of samples\n",
    "    for j, (mean, covariance, sample_count) in enumerate(zip(means_, covariances_, n_samples_comp)):\n",
    "        if sample_count > 0:  # Only sample if we need samples from this component\n",
    "            dist = torch.distributions.MultivariateNormal(\n",
    "                mean, covariance\n",
    "            )\n",
    "            samples = dist.sample((sample_count,))\n",
    "            X.append(samples)\n",
    "            y.append(torch.full((sample_count,), j, dtype=torch.int64))\n",
    "    \n",
    "    # Concatenate all samples and labels into single tensors\n",
    "    X = torch.vstack(X)\n",
    "    y = torch.cat(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.03887747, -2.9453815 ,  0.43721818, -0.20162165,  0.28700438,\n",
       "         0.1723324 ,  0.81485445,  1.7054237 ,  0.08203473, -1.72305909,\n",
       "         1.00713371,  0.04058859,  0.19500022,  1.00962552,  1.61513841,\n",
       "        -2.42326199, 13.6384044 ,  3.04574583]),\n",
       " 0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm_samples = sample(skgmm.means_, skgmm.covariances_, skgmm.weights_, n_samples = N_SAMPLES)\n",
    "\n",
    "skgmm_X, skgmm_y = skgmm_samples\n",
    "skgmm_X[IDX], skgmm_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-3.32496524e-02, -2.98268887e+00,  4.24690527e-01, -1.67278872e-01,\n",
       "         2.24809896e-01,  1.06553346e-01,  6.26317064e-01,  1.26015957e+00,\n",
       "         2.01741825e-03, -2.07779531e+00,  7.85901517e-01,  2.26804101e-01,\n",
       "         8.27804447e-01,  5.43464053e-01,  1.54425686e+00, -2.70189306e+00,\n",
       "         1.33966804e+01,  3.17510242e+00]),\n",
       " 0)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = sample(means, covar, weights, n_samples = N_SAMPLES)\n",
    "\n",
    "X, y = samples\n",
    "X[IDX], y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0756, -3.2072,  0.2560,  0.1855,  1.0395,  0.4390,  0.9301,  2.0937,\n",
       "         -0.0612, -2.1749,  1.0848, -0.6334, -0.5247,  1.3095,  2.3578, -2.5904,\n",
       "          5.2245,  2.1991]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_samples = torch_sample(trained_model.means, trained_model.covariances, trained_model.weights, n_samples = N_SAMPLES)\n",
    "train_model_X, train_model_y = train_model_samples\n",
    "train_model_X[IDX], train_model_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 0.0756, -3.2072,  0.2560,  0.1855,  1.0395,  0.4390,  0.9301,  2.0937,\n",
       "         -0.0612, -2.1749,  1.0848, -0.6334, -0.5247,  1.3095,  2.3578, -2.5904,\n",
       "          5.2245,  2.1991]),\n",
       " tensor(0))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_samples = torch_sample(gmm_lightning_module.gmm_module.means, gmm_lightning_module.gmm_module.covariances, gmm_lightning_module.gmm_module.weights, n_samples = N_SAMPLES)\n",
    "gmm_lightning_X, gmm_lightning_y = train_model_samples\n",
    "gmm_lightning_X[IDX], gmm_lightning_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSynth-BNsxhSIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
