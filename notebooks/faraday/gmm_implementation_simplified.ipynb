{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_data = pd.read_csv(\"../../data/processed/historical/train/lcl_data.csv\")\n",
    "df_100K = full_data.sample(100000, random_state=0)\n",
    "df_100K.to_csv(\"../../data/processed/historical/train/lcl_data_100K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "RANDOM_STATE = 0\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(RANDOM_STATE)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from opensynth.data_modules.lcl_data_module import LCLDataModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = Path(\"../../data/processed/historical/train/lcl_data_25K.csv\")\n",
    "stats_path = Path(\"../../data/processed/historical/train/mean_std.csv\")\n",
    "outlier_path = Path(\"../../data/processed/historical/train/outliers.csv\")\n",
    "\n",
    "dm = LCLDataModule(data_path=data_path, stats_path=stats_path, batch_size=25000, n_samples=25000)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaradayVAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder_layers): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=32, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (latent): Linear(in_features=18, out_features=16, bias=True)\n",
       "    (latent_activations): GELU(approximate='none')\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=512, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (reparametriser): ReparametrisationModule(\n",
       "    (mean): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from opensynth.models.faraday import FaradayVAE\n",
    "vae_model = torch.load(\"vae_model.pt\")\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensynth.models.faraday.gaussian_mixture.prepare_gmm_input import encode_data_for_gmm\n",
    "\n",
    "next_batch = next(iter(dm.train_dataloader()))\n",
    "input_tensor = encode_data_for_gmm(data=next_batch, vae_module=vae_model)\n",
    "input_data = input_tensor.detach().numpy()\n",
    "n_samples = len(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 250\n",
    "REG_COVAR = 1e-4\n",
    "EPOCHS = 25\n",
    "IDX = 0\n",
    "CONVERGENCE_TOL = 1e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0195, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm import gmm_utils\n",
    "\n",
    "labels_, means_, responsibilities_ = gmm_utils.initialise_centroids(\n",
    "        X=input_data, n_components=N_COMPONENTS\n",
    "    )\n",
    "print(labels_.dtype, responsibilities_.dtype, means_.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.1549)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "print(gmm_init_params[\"precision_cholesky\"][IDX][0][0])\n",
    "print(gmm_init_params[\"weights\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 4.1548590660095215. Initial mean: 0.17847225069999695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.5466245412826538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.23698663711547852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.15521585941314697\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.11739683151245117\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.09774953126907349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.08635258674621582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.07510387897491455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.058798372745513916\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.04888087511062622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.04147988557815552\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.032204270362854004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.026453495025634766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.022479653358459473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.017785489559173584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.014730274677276611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.013055741786956787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.012066006660461426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.010769903659820557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [00:10<00:03,  1.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Change: 0.009308397769927979\n",
      "Converged: True. Number of iterations: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params, training_loop\n",
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureModel\n",
    "\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "\n",
    "means = gmm_init_params[\"means\"].detach().numpy()\n",
    "weights = gmm_init_params[\"weights\"].detach().numpy()\n",
    "prec_chol = gmm_init_params[\"precision_cholesky\"].detach().numpy()\n",
    "print(f\"Initial prec chol: {prec_chol[IDX][0][0]}. Initial mean: {means[IDX][0]}\")\n",
    "\n",
    "torch_gmm = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "torch_gmm.initialise(gmm_init_params)\n",
    "trained_model = training_loop(model=torch_gmm, data=input_tensor, max_iter=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from scipy import linalg\n",
    "\n",
    "def is_symmetric_positive_definite(covariance):\n",
    "    is_symmetric = np.all([np.allclose(covariance[i], covariance[i].T) for i in range(covariance.shape[0])])\n",
    "    is_positive_definite = np.all([np.all(np.linalg.eigvalsh(covariance[i]) > 0.0) for i in range(covariance.shape[0])])\n",
    "    return is_symmetric and is_positive_definite\n",
    "\n",
    "def _estimate_gaussian_parameters(X, resp, reg_covar=REG_COVAR):\n",
    "    nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "    n_components, n_features = means.shape\n",
    "    covariances = np.empty((n_components, n_features, n_features))\n",
    "    for k in range(n_components):\n",
    "        diff = X - means[k]\n",
    "        covariances[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]\n",
    "        covariances[k].flat[:: n_features + 1] += reg_covar\n",
    "\n",
    "    check_covariances = is_symmetric_positive_definite(covariances)\n",
    "    if not check_covariances:\n",
    "        raise ValueError(\"Covariance matrix is not positive definite.\")\n",
    "    return nk, means, covariances\n",
    "\n",
    "def _compute_precision_cholesky(covariances):\n",
    "    estimate_precision_error_message = (\n",
    "        \"Fitting the mixture model failed because some components have \"\n",
    "        \"ill-defined empirical covariance (for instance caused by singleton \"\n",
    "        \"or collapsed samples). Try to decrease the number of components, \"\n",
    "        \"or increase reg_covar.\"\n",
    "    )\n",
    "\n",
    "    n_components, n_features, _ = covariances.shape\n",
    "    precisions_chol = np.empty((n_components, n_features, n_features))\n",
    "    for k, covariance in enumerate(covariances):\n",
    "        try:\n",
    "            cov_chol = linalg.cholesky(covariance, lower=True)\n",
    "        except linalg.LinAlgError:\n",
    "            raise ValueError(estimate_precision_error_message)\n",
    "        precisions_chol[k] = linalg.solve_triangular(\n",
    "            cov_chol, np.eye(n_features), lower=True\n",
    "        ).T\n",
    "    return precisions_chol\n",
    "\n",
    "def _compute_log_det_cholesky(matrix_chol, n_features):\n",
    "    n_components, _, _ = matrix_chol.shape\n",
    "    log_det_chol = np.sum(\n",
    "        np.log(matrix_chol.reshape(n_components, -1)[:, :: n_features + 1]), 1\n",
    "    )\n",
    "    return log_det_chol\n",
    "\n",
    "def _estimate_log_gaussian_prob(X, means, precisions_chol):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_components, _ = means.shape\n",
    "\n",
    "    log_det = _compute_log_det_cholesky(precisions_chol, n_features)\n",
    "\n",
    "    log_prob = np.empty((n_samples, n_components))\n",
    "    for k, (mu, prec_chol) in enumerate(zip(means, precisions_chol)):\n",
    "        y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n",
    "        log_prob[:, k] = np.sum(np.square(y), axis=1)\n",
    "    return -0.5 * (n_features * np.log(2 * np.pi) + log_prob) + log_det\n",
    "\n",
    "def _estimate_log_weights(weights):\n",
    "        return np.log(weights)\n",
    "\n",
    "def _estimate_weighted_log_prob(X, means, precisions_chol, weights):\n",
    "        return _estimate_log_gaussian_prob(X, means, precisions_chol) + _estimate_log_weights(weights)\n",
    "\n",
    "\n",
    "def _estimate_log_prob_resp(X, means, precisions_chol, weights):\n",
    "    weighted_log_prob = _estimate_weighted_log_prob(X, means, precisions_chol, weights)\n",
    "    log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
    "    with np.errstate(under=\"ignore\"):\n",
    "        log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]\n",
    "    return log_prob_norm, log_resp\n",
    "\n",
    "def _e_step(X,means, precisions_chol, weights):\n",
    "    log_prob_norm, log_resp = _estimate_log_prob_resp(X, means, precisions_chol, weights)\n",
    "    return np.mean(log_prob_norm), log_resp\n",
    "\n",
    "def _m_step(X, log_reponsibilities, reg_covar=REG_COVAR):\n",
    "\n",
    "    weights_, means_, covariances_ = _estimate_gaussian_parameters(X,np.exp(log_reponsibilities),reg_covar=reg_covar)\n",
    "    weights_ /= weights_.sum()\n",
    "\n",
    "    precision_cholesky_ = _compute_precision_cholesky(covariances=covariances_)\n",
    "\n",
    "    return precision_cholesky_, weights_, means_, covariances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 4.1548590660095215. Initial mean: 0.17847225069999695\n",
      "Old Prec Chol: 4.1548590660095215. Old means: 0.17847225069999695\n",
      "New prec chol: 4.264129574723797. New means: 0.15994199961644728\n",
      "Change: inf\n",
      "Old Prec Chol: 4.264129574723797. Old means: 0.15994199961644728\n",
      "New prec chol: 4.316532703063464. New means: 0.13492338340899412\n",
      "Change: 0.5462640519048083\n",
      "Old Prec Chol: 4.316532703063464. Old means: 0.13492338340899412\n",
      "New prec chol: 4.175878808822229. New means: 0.11099307058643207\n",
      "Change: 0.2368447243335936\n",
      "Old Prec Chol: 4.175878808822229. Old means: 0.11099307058643207\n",
      "New prec chol: 3.9374693321175926. New means: 0.09106721682231624\n",
      "Change: 0.15513712903174603\n",
      "Old Prec Chol: 3.9374693321175926. Old means: 0.09106721682231624\n",
      "New prec chol: 3.8129173430607217. New means: 0.07953399423854603\n",
      "Change: 0.11734342660665598\n",
      "Old Prec Chol: 3.8129173430607217. Old means: 0.07953399423854603\n",
      "New prec chol: 3.761243859543583. New means: 0.06862377937016459\n",
      "Change: 0.09770968886227283\n",
      "Old Prec Chol: 3.761243859543583. Old means: 0.06862377937016459\n",
      "New prec chol: 3.730062787163844. New means: 0.059306825926168025\n",
      "Change: 0.08634360727989743\n",
      "Old Prec Chol: 3.730062787163844. Old means: 0.059306825926168025\n",
      "New prec chol: 3.731395434347445. New means: 0.050447893427406354\n",
      "Change: 0.0750644304267577\n",
      "Old Prec Chol: 3.731395434347445. Old means: 0.050447893427406354\n",
      "New prec chol: 3.775124047509824. New means: 0.03962852951132849\n",
      "Change: 0.058727359327232054\n",
      "Old Prec Chol: 3.775124047509824. Old means: 0.03962852951132849\n",
      "New prec chol: 3.8433270805910347. New means: 0.02911534963198337\n",
      "Change: 0.04889103514233395\n",
      "Old Prec Chol: 3.8433270805910347. Old means: 0.02911534963198337\n",
      "New prec chol: 3.864820818324765. New means: 0.022998005261061976\n",
      "Change: 0.04153834878465912\n",
      "Old Prec Chol: 3.864820818324765. Old means: 0.022998005261061976\n",
      "New prec chol: 3.8680056766173894. New means: 0.018499461134415123\n",
      "Change: 0.03219294269767781\n",
      "Old Prec Chol: 3.8680056766173894. Old means: 0.018499461134415123\n",
      "New prec chol: 3.855305314338913. New means: 0.014354450650698413\n",
      "Change: 0.02643288467026017\n",
      "Old Prec Chol: 3.855305314338913. Old means: 0.014354450650698413\n",
      "New prec chol: 3.827245791585155. New means: 0.009790427585121938\n",
      "Change: 0.02253581595582954\n",
      "Old Prec Chol: 3.827245791585155. Old means: 0.009790427585121938\n",
      "New prec chol: 3.808923404691336. New means: 0.005145292788912848\n",
      "Change: 0.017750735047463606\n",
      "Old Prec Chol: 3.808923404691336. Old means: 0.005145292788912848\n",
      "New prec chol: 3.793216479175072. New means: 0.0025659321318203475\n",
      "Change: 0.01471410653395766\n",
      "Old Prec Chol: 3.793216479175072. Old means: 0.0025659321318203475\n",
      "New prec chol: 3.7828806053036774. New means: 0.0010361231777877276\n",
      "Change: 0.013068588309794404\n",
      "Old Prec Chol: 3.7828806053036774. Old means: 0.0010361231777877276\n",
      "New prec chol: 3.77992013704454. New means: -0.00018815937114863654\n",
      "Change: 0.012094278841670025\n",
      "Old Prec Chol: 3.77992013704454. Old means: -0.00018815937114863654\n",
      "New prec chol: 3.7777747082581787. New means: -0.0019551179270437037\n",
      "Change: 0.010704145156573364\n",
      "Old Prec Chol: 3.7777747082581787. Old means: -0.0019551179270437037\n",
      "New prec chol: 3.7524345675675215. New means: -0.0018778906171293744\n",
      "Change: 0.009243796652510294\n",
      "Converged: True. Number of iterations: 19\n"
     ]
    }
   ],
   "source": [
    "means = gmm_init_params[\"means\"].detach().numpy()\n",
    "weights = gmm_init_params[\"weights\"].detach().numpy()\n",
    "prec_chol = gmm_init_params[\"precision_cholesky\"].detach().numpy()\n",
    "\n",
    "print(f\"Initial prec chol: {prec_chol[IDX][0][0]}. Initial mean: {means[IDX][0]}\")\n",
    "\n",
    "converged = False\n",
    "lower_bound = -np.inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    prev_lower_bound = lower_bound\n",
    "\n",
    "    print(f\"Old Prec Chol: {prec_chol[IDX][0][0]}. Old means: {means[IDX][0]}\")\n",
    "    log_prob, log_resp = _e_step(input_data, means, prec_chol, weights)\n",
    "    prec_chol, weights, means, covar = _m_step(input_data, log_resp)\n",
    "\n",
    "    print(f\"New prec chol: {prec_chol[IDX][0][0]}. New means: {means[IDX][0]}\")\n",
    "\n",
    "    # Converegence\n",
    "    lower_bound = log_prob\n",
    "    change = abs(lower_bound - prev_lower_bound)\n",
    "    print(f\"Change: {change}\")\n",
    "    if change < CONVERGENCE_TOL:\n",
    "        converged = True\n",
    "        break\n",
    "\n",
    "print(f'Converged: {converged}. Number of iterations: {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 1\t time lapse 4.53057s\t ll change inf\n",
      "  Iteration 2\t time lapse 2.58428s\t ll change 0.55539\n",
      "  Iteration 3\t time lapse 2.58921s\t ll change 0.24410\n",
      "  Iteration 4\t time lapse 2.05588s\t ll change 0.16252\n",
      "  Iteration 5\t time lapse 3.81376s\t ll change 0.12118\n",
      "  Iteration 6\t time lapse 2.24481s\t ll change 0.10090\n",
      "  Iteration 7\t time lapse 2.11445s\t ll change 0.08873\n",
      "  Iteration 8\t time lapse 2.25663s\t ll change 0.07771\n",
      "  Iteration 9\t time lapse 2.43798s\t ll change 0.05981\n",
      "  Iteration 10\t time lapse 2.23437s\t ll change 0.04934\n",
      "  Iteration 11\t time lapse 2.00195s\t ll change 0.04429\n",
      "  Iteration 12\t time lapse 2.22959s\t ll change 0.03445\n",
      "  Iteration 13\t time lapse 2.11412s\t ll change 0.02836\n",
      "  Iteration 14\t time lapse 2.09645s\t ll change 0.02424\n",
      "  Iteration 15\t time lapse 2.15970s\t ll change 0.02104\n",
      "  Iteration 16\t time lapse 2.14948s\t ll change 0.01738\n",
      "  Iteration 17\t time lapse 2.01346s\t ll change 0.01459\n",
      "  Iteration 18\t time lapse 2.40509s\t ll change 0.01319\n",
      "  Iteration 19\t time lapse 2.21964s\t ll change 0.01202\n",
      "  Iteration 20\t time lapse 1.71744s\t ll change 0.01063\n",
      "  Iteration 21\t time lapse 1.91227s\t ll change 0.00935\n",
      "Initialization converged. time lapse 49.88124s\t lower bound 0.07291.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "init_weights = gmm_init_params[\"weights\"]\n",
    "init_means = gmm_init_params[\"means\"]\n",
    "\n",
    "skgmm = GaussianMixture(n_components=N_COMPONENTS, covariance_type='full', tol=CONVERGENCE_TOL, max_iter=EPOCHS, random_state=0, means_init = init_means, weights_init=init_weights, verbose=2, verbose_interval=1)\n",
    "skgmm.fit(input_data)\n",
    "skgmm_pred = skgmm.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 21)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm.converged_, skgmm.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_tensor: torch.Tensor):\n",
    "        self.data = data_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "class CustomDataModule(LightningDataModule):\n",
    "    def __init__(self, data_tensor: torch.Tensor, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.data_tensor = data_tensor\n",
    "        self.batch_size = batch_size\n",
    "    def setup(self, stage=\"\"):\n",
    "        self.custom_ds = CustomDataset(self.data_tensor)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.custom_ds, batch_size=self.batch_size, shuffle=False, generator=g, worker_init_fn=seed_worker)\n",
    "    \n",
    "custom_dm = CustomDataModule(data_tensor=input_tensor, batch_size=25000)\n",
    "custom_dm.setup(stage=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(next(iter(custom_dm.train_dataloader()))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name                      | Type                    | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | gmm_module                | GaussianMixtureModel    | 0      | train\n",
      "1 | vae_module                | FaradayVAE              | 402 K  | eval \n",
      "2 | weight_metric             | WeightsMetric           | 0      | train\n",
      "3 | mean_metric               | MeansMetric             | 0      | train\n",
      "4 | precision_cholesky_metric | PrecisionCholeskyMetric | 0      | train\n",
      "5 | covariance_metric         | CovarianceMetric        | 0      | train\n",
      "6 | log_prob                  | LogProbMetric           | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "402 K     Trainable params\n",
      "0         Non-trainable params\n",
      "402 K     Total params\n",
      "1.609     Total estimated model params size (MB)\n",
      "6         Modules in train mode\n",
      "32        Modules in eval mode\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 4.1548590660095215. Initial mean: 0.17847225069999695\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.30it/s, v_num=20]Local weights at rank: 0 - means: 0.0063, 0.1599\n",
      "Reduced weights, means: 0.0063, 0.1599\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  1.49it/s, v_num=20]Local weights at rank: 0 - means: 0.0059, 0.1349\n",
      "Reduced weights, means: 0.0059, 0.1349\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  2.27it/s, v_num=20]Local weights at rank: 0 - means: 0.0058, 0.1109\n",
      "Reduced weights, means: 0.0058, 0.1109\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  2.59it/s, v_num=20]Local weights at rank: 0 - means: 0.0058, 0.0909\n",
      "Reduced weights, means: 0.0058, 0.0909\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  2.26it/s, v_num=20]Local weights at rank: 0 - means: 0.0056, 0.0793\n",
      "Reduced weights, means: 0.0056, 0.0793\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  2.92it/s, v_num=20]Local weights at rank: 0 - means: 0.0053, 0.0683\n",
      "Reduced weights, means: 0.0053, 0.0683\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=20]Local weights at rank: 0 - means: 0.0050, 0.0589\n",
      "Reduced weights, means: 0.0050, 0.0589\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  3.00it/s, v_num=20]Local weights at rank: 0 - means: 0.0048, 0.0499\n",
      "Reduced weights, means: 0.0048, 0.0499\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  2.09it/s, v_num=20]Local weights at rank: 0 - means: 0.0047, 0.0389\n",
      "Reduced weights, means: 0.0047, 0.0389\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s, v_num=20]Local weights at rank: 0 - means: 0.0046, 0.0289\n",
      "Reduced weights, means: 0.0046, 0.0289\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  2.29it/s, v_num=20]Local weights at rank: 0 - means: 0.0047, 0.0231\n",
      "Reduced weights, means: 0.0047, 0.0231\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  2.62it/s, v_num=20]Local weights at rank: 0 - means: 0.0047, 0.0185\n",
      "Reduced weights, means: 0.0047, 0.0185\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  2.90it/s, v_num=20]Local weights at rank: 0 - means: 0.0047, 0.0142\n",
      "Reduced weights, means: 0.0047, 0.0142\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  2.16it/s, v_num=20]Local weights at rank: 0 - means: 0.0047, 0.0095\n",
      "Reduced weights, means: 0.0047, 0.0095\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  1.83it/s, v_num=20]Local weights at rank: 0 - means: 0.0046, 0.0050\n",
      "Reduced weights, means: 0.0046, 0.0050\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  2.34it/s, v_num=20]Local weights at rank: 0 - means: 0.0046, 0.0025\n",
      "Reduced weights, means: 0.0046, 0.0025\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  2.41it/s, v_num=20]Local weights at rank: 0 - means: 0.0045, 0.0012\n",
      "Reduced weights, means: 0.0045, 0.0012\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  2.35it/s, v_num=20]Local weights at rank: 0 - means: 0.0045, -0.0003\n",
      "Reduced weights, means: 0.0045, -0.0003\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  2.88it/s, v_num=20]Local weights at rank: 0 - means: 0.0044, -0.0019\n",
      "Reduced weights, means: 0.0044, -0.0019\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.44it/s, v_num=20]Local weights at rank: 0 - means: 0.0044, -0.0017\n",
      "Reduced weights, means: 0.0044, -0.0017\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=20]\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureLightningModule\n",
    "gmm_module = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "gmm_module.initialise(gmm_init_params)\n",
    "print(f\"Initial prec chol: {gmm_module.precision_cholesky[IDX][0][0]}. Initial mean: {gmm_module.means[IDX][0]}\")\n",
    "\n",
    "gmm_lightning_module = GaussianMixtureLightningModule(\n",
    "    gmm_module = gmm_module,\n",
    "    vae_module = vae_model,\n",
    "    num_components = gmm_module.num_components,\n",
    "    num_features = gmm_module.num_features,\n",
    "    reg_covar = gmm_module.reg_covar,\n",
    "    convergence_tolerance = CONVERGENCE_TOL,\n",
    "    compute_on_batch=True\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=EPOCHS, accelerator=\"cpu\", deterministic=True )\n",
    "trainer.fit(gmm_lightning_module, custom_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0044), tensor(-0.0017))"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_module.gmm_module.weights[0], gmm_lightning_module.gmm_module.means[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0044), tensor(-0.0017))"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_module.weight_metric.compute()[0], gmm_lightning_module.mean_metric.compute()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.035201</td>\n",
       "      <td>-0.001878</td>\n",
       "      <td>-0.001677</td>\n",
       "      <td>-0.001677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.627329</td>\n",
       "      <td>-1.776944</td>\n",
       "      <td>-1.777669</td>\n",
       "      <td>-1.777669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.842405</td>\n",
       "      <td>-0.960595</td>\n",
       "      <td>-0.959451</td>\n",
       "      <td>-0.959451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.525421</td>\n",
       "      <td>1.739976</td>\n",
       "      <td>1.740235</td>\n",
       "      <td>1.740235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.530031</td>\n",
       "      <td>0.615125</td>\n",
       "      <td>0.616592</td>\n",
       "      <td>0.616592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.081067</td>\n",
       "      <td>-0.079712</td>\n",
       "      <td>-0.079611</td>\n",
       "      <td>-0.079611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.521916</td>\n",
       "      <td>-0.673630</td>\n",
       "      <td>-0.674024</td>\n",
       "      <td>-0.674024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.303917</td>\n",
       "      <td>3.522102</td>\n",
       "      <td>3.519754</td>\n",
       "      <td>3.519754</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.257689</td>\n",
       "      <td>-0.288638</td>\n",
       "      <td>-0.288372</td>\n",
       "      <td>-0.288372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.700934</td>\n",
       "      <td>-2.087236</td>\n",
       "      <td>-2.089393</td>\n",
       "      <td>-2.089393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.440692</td>\n",
       "      <td>-0.573802</td>\n",
       "      <td>-0.573840</td>\n",
       "      <td>-0.573840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.328725</td>\n",
       "      <td>-1.367364</td>\n",
       "      <td>-1.367639</td>\n",
       "      <td>-1.367639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.347468</td>\n",
       "      <td>-2.393911</td>\n",
       "      <td>-2.391549</td>\n",
       "      <td>-2.391549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1.036309</td>\n",
       "      <td>1.029411</td>\n",
       "      <td>1.027942</td>\n",
       "      <td>1.027942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.149675</td>\n",
       "      <td>1.286874</td>\n",
       "      <td>1.288397</td>\n",
       "      <td>1.288397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.210422</td>\n",
       "      <td>-1.397695</td>\n",
       "      <td>-1.399512</td>\n",
       "      <td>-1.399512</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.242967</td>\n",
       "      <td>7.670277</td>\n",
       "      <td>7.657731</td>\n",
       "      <td>7.657731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.957348</td>\n",
       "      <td>2.777244</td>\n",
       "      <td>2.777091</td>\n",
       "      <td>2.777091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0  -0.035201 -0.001878 -0.001677  -0.001677\n",
       "1  -1.627329 -1.776944 -1.777669  -1.777669\n",
       "2  -0.842405 -0.960595 -0.959451  -0.959451\n",
       "3   1.525421  1.739976  1.740235   1.740235\n",
       "4   0.530031  0.615125  0.616592   0.616592\n",
       "5  -0.081067 -0.079712 -0.079611  -0.079611\n",
       "6  -0.521916 -0.673630 -0.674024  -0.674024\n",
       "7   3.303917  3.522102  3.519754   3.519754\n",
       "8  -0.257689 -0.288638 -0.288372  -0.288372\n",
       "9  -1.700934 -2.087236 -2.089393  -2.089393\n",
       "10 -0.440692 -0.573802 -0.573840  -0.573840\n",
       "11 -1.328725 -1.367364 -1.367639  -1.367639\n",
       "12 -2.347468 -2.393911 -2.391549  -2.391549\n",
       "13  1.036309  1.029411  1.027942   1.027942\n",
       "14  1.149675  1.286874  1.288397   1.288397\n",
       "15 -1.210422 -1.397695 -1.399512  -1.399512\n",
       "16  7.242967  7.670277  7.657731   7.657731\n",
       "17  2.957348  2.777244  2.777091   2.777091"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_means = pd.DataFrame()\n",
    "df_compare_means[\"skgmm\"] = skgmm.means_[IDX]\n",
    "df_compare_means[\"numpy\"] = means[IDX]\n",
    "df_compare_means[\"torch\"] = trained_model.means[IDX]\n",
    "df_compare_means[\"lightning\"] = gmm_lightning_module.gmm_module.means[IDX]\n",
    "df_compare_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1785, -2.7549, -1.0892,  1.7319,  0.2749, -0.0532, -0.9788,  3.2775,\n",
       "        -0.2790, -2.2910, -0.6581, -1.5413, -1.2498,  0.9345,  0.9561, -2.0828,\n",
       "         5.9111,  3.9389])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_init_params[\"means\"][IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.075459</td>\n",
       "      <td>0.071019</td>\n",
       "      <td>0.071599</td>\n",
       "      <td>0.071599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.202008</td>\n",
       "      <td>-0.201330</td>\n",
       "      <td>-0.204387</td>\n",
       "      <td>-0.204387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.111972</td>\n",
       "      <td>-0.098755</td>\n",
       "      <td>-0.099446</td>\n",
       "      <td>-0.099446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.111245</td>\n",
       "      <td>0.102897</td>\n",
       "      <td>0.103970</td>\n",
       "      <td>0.103970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.023585</td>\n",
       "      <td>-0.013192</td>\n",
       "      <td>-0.012076</td>\n",
       "      <td>-0.012076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.013760</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.009897</td>\n",
       "      <td>0.009897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.139312</td>\n",
       "      <td>-0.135811</td>\n",
       "      <td>-0.136264</td>\n",
       "      <td>-0.136264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.074386</td>\n",
       "      <td>-0.095631</td>\n",
       "      <td>-0.094559</td>\n",
       "      <td>-0.094559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.016463</td>\n",
       "      <td>-0.016869</td>\n",
       "      <td>-0.016866</td>\n",
       "      <td>-0.016866</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.039057</td>\n",
       "      <td>-0.069567</td>\n",
       "      <td>-0.071000</td>\n",
       "      <td>-0.071000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.075960</td>\n",
       "      <td>-0.077624</td>\n",
       "      <td>-0.077229</td>\n",
       "      <td>-0.077229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.218067</td>\n",
       "      <td>-0.191217</td>\n",
       "      <td>-0.193322</td>\n",
       "      <td>-0.193322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.211695</td>\n",
       "      <td>0.236262</td>\n",
       "      <td>0.236683</td>\n",
       "      <td>0.236683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.043573</td>\n",
       "      <td>-0.066160</td>\n",
       "      <td>-0.065174</td>\n",
       "      <td>-0.065174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.078512</td>\n",
       "      <td>-0.057966</td>\n",
       "      <td>-0.056732</td>\n",
       "      <td>-0.056732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.150342</td>\n",
       "      <td>-0.161660</td>\n",
       "      <td>-0.163881</td>\n",
       "      <td>-0.163881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.047617</td>\n",
       "      <td>-0.100941</td>\n",
       "      <td>-0.102142</td>\n",
       "      <td>-0.102142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.010415</td>\n",
       "      <td>-0.044385</td>\n",
       "      <td>-0.044015</td>\n",
       "      <td>-0.044015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0   0.075459  0.071019  0.071599   0.071599\n",
       "1  -0.202008 -0.201330 -0.204387  -0.204387\n",
       "2  -0.111972 -0.098755 -0.099446  -0.099446\n",
       "3   0.111245  0.102897  0.103970   0.103970\n",
       "4  -0.023585 -0.013192 -0.012076  -0.012076\n",
       "5   0.013760  0.009636  0.009897   0.009897\n",
       "6  -0.139312 -0.135811 -0.136264  -0.136264\n",
       "7  -0.074386 -0.095631 -0.094559  -0.094559\n",
       "8  -0.016463 -0.016869 -0.016866  -0.016866\n",
       "9  -0.039057 -0.069567 -0.071000  -0.071000\n",
       "10 -0.075960 -0.077624 -0.077229  -0.077229\n",
       "11 -0.218067 -0.191217 -0.193322  -0.193322\n",
       "12  0.211695  0.236262  0.236683   0.236683\n",
       "13 -0.043573 -0.066160 -0.065174  -0.065174\n",
       "14 -0.078512 -0.057966 -0.056732  -0.056732\n",
       "15 -0.150342 -0.161660 -0.163881  -0.163881\n",
       "16 -0.047617 -0.100941 -0.102142  -0.102142\n",
       "17  0.010415 -0.044385 -0.044015  -0.044015"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_covar = pd.DataFrame()\n",
    "df_compare_covar[\"skgmm\"] = skgmm.covariances_[IDX][0]\n",
    "df_compare_covar[\"numpy\"] = covar[IDX][0]\n",
    "df_compare_covar[\"torch\"] = trained_model.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar[\"lightning\"] = gmm_lightning_module.gmm_module.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.640359</td>\n",
       "      <td>3.752435</td>\n",
       "      <td>3.737195</td>\n",
       "      <td>3.737195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.480077</td>\n",
       "      <td>2.400315</td>\n",
       "      <td>2.415535</td>\n",
       "      <td>2.415535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.012257</td>\n",
       "      <td>2.680574</td>\n",
       "      <td>2.668036</td>\n",
       "      <td>2.668036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.922032</td>\n",
       "      <td>-1.395591</td>\n",
       "      <td>-1.409341</td>\n",
       "      <td>-1.409341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-3.007662</td>\n",
       "      <td>-3.242618</td>\n",
       "      <td>-3.273510</td>\n",
       "      <td>-3.273510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.049216</td>\n",
       "      <td>-3.703160</td>\n",
       "      <td>-3.714443</td>\n",
       "      <td>-3.714443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>3.224421</td>\n",
       "      <td>4.641292</td>\n",
       "      <td>4.642696</td>\n",
       "      <td>4.642696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.447998</td>\n",
       "      <td>13.521707</td>\n",
       "      <td>13.529406</td>\n",
       "      <td>13.529406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.293808</td>\n",
       "      <td>1.508207</td>\n",
       "      <td>1.512385</td>\n",
       "      <td>1.512385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-7.302855</td>\n",
       "      <td>-5.594008</td>\n",
       "      <td>-5.637901</td>\n",
       "      <td>-5.637901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>3.359134</td>\n",
       "      <td>1.835447</td>\n",
       "      <td>1.833906</td>\n",
       "      <td>1.833906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>6.409876</td>\n",
       "      <td>8.501468</td>\n",
       "      <td>8.585663</td>\n",
       "      <td>8.585663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.518190</td>\n",
       "      <td>-6.369786</td>\n",
       "      <td>-6.386127</td>\n",
       "      <td>-6.386127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-7.859264</td>\n",
       "      <td>-4.621736</td>\n",
       "      <td>-4.649794</td>\n",
       "      <td>-4.649794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.012628</td>\n",
       "      <td>4.818146</td>\n",
       "      <td>4.855773</td>\n",
       "      <td>4.855773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.653822</td>\n",
       "      <td>2.502301</td>\n",
       "      <td>2.516105</td>\n",
       "      <td>2.516105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>3.977935</td>\n",
       "      <td>4.968980</td>\n",
       "      <td>4.951368</td>\n",
       "      <td>4.951368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6.615918</td>\n",
       "      <td>4.813634</td>\n",
       "      <td>4.741772</td>\n",
       "      <td>4.741772</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        skgmm      numpy      torch  lightning\n",
       "0    3.640359   3.752435   3.737195   3.737195\n",
       "1    2.480077   2.400315   2.415535   2.415535\n",
       "2    3.012257   2.680574   2.668036   2.668036\n",
       "3   -0.922032  -1.395591  -1.409341  -1.409341\n",
       "4   -3.007662  -3.242618  -3.273510  -3.273510\n",
       "5   -5.049216  -3.703160  -3.714443  -3.714443\n",
       "6    3.224421   4.641292   4.642696   4.642696\n",
       "7   12.447998  13.521707  13.529406  13.529406\n",
       "8    0.293808   1.508207   1.512385   1.512385\n",
       "9   -7.302855  -5.594008  -5.637901  -5.637901\n",
       "10   3.359134   1.835447   1.833906   1.833906\n",
       "11   6.409876   8.501468   8.585663   8.585663\n",
       "12  -5.518190  -6.369786  -6.386127  -6.386127\n",
       "13  -7.859264  -4.621736  -4.649794  -4.649794\n",
       "14   5.012628   4.818146   4.855773   4.855773\n",
       "15   4.653822   2.502301   2.516105   2.516105\n",
       "16   3.977935   4.968980   4.951368   4.951368\n",
       "17   6.615918   4.813634   4.741772   4.741772"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_pre_chol = pd.DataFrame()\n",
    "df_compare_pre_chol[\"skgmm\"] = skgmm.precisions_cholesky_[IDX][0]\n",
    "df_compare_pre_chol[\"numpy\"] = prec_chol[IDX][0]\n",
    "df_compare_pre_chol[\"torch\"] = trained_model.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol[\"lightning\"] = gmm_lightning_module.gmm_module.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004774</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.004385</td>\n",
       "      <td>0.004385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029848</td>\n",
       "      <td>0.041667</td>\n",
       "      <td>0.041665</td>\n",
       "      <td>0.041665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021730</td>\n",
       "      <td>0.022938</td>\n",
       "      <td>0.022917</td>\n",
       "      <td>0.022917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002641</td>\n",
       "      <td>0.002473</td>\n",
       "      <td>0.002478</td>\n",
       "      <td>0.002478</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006420</td>\n",
       "      <td>0.005413</td>\n",
       "      <td>0.005415</td>\n",
       "      <td>0.005415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.005059</td>\n",
       "      <td>0.005059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      skgmm     numpy     torch  lightning\n",
       "0  0.004774  0.004385  0.004385   0.004385\n",
       "1  0.000160  0.000160  0.000160   0.000160\n",
       "2  0.029848  0.041667  0.041665   0.041665\n",
       "3  0.021730  0.022938  0.022917   0.022917\n",
       "4  0.002641  0.002473  0.002478   0.002478\n",
       "5  0.000160  0.000160  0.000160   0.000160\n",
       "6  0.006420  0.005413  0.005415   0.005415\n",
       "7  0.004994  0.005059  0.005059   0.005059\n",
       "8  0.000600  0.000600  0.000600   0.000600\n",
       "9  0.000480  0.000480  0.000480   0.000480"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_weights = pd.DataFrame()\n",
    "df_compare_weights[\"skgmm\"] = skgmm.weights_[:10]\n",
    "df_compare_weights[\"numpy\"] = weights[:10]\n",
    "df_compare_weights[\"torch\"] = trained_model.weights[:10]\n",
    "df_compare_weights[\"lightning\"] = gmm_lightning_module.gmm_module.weights.detach().numpy()[:10]\n",
    "df_compare_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(means_, covariances_, weights_, n_samples):\n",
    "    rng = np.random.RandomState(RANDOM_STATE)\n",
    "    n_samples_comp = rng.multinomial(n_samples, weights_)\n",
    "    \n",
    "    X = np.vstack(\n",
    "            [\n",
    "                rng.multivariate_normal(mean, covariance, int(sample))\n",
    "                for (mean, covariance, sample) in zip(\n",
    "                    means_, covariances_, n_samples_comp\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    y = np.concatenate(\n",
    "        [np.full(sample, j, dtype=int) for j, sample in enumerate(n_samples_comp)]\n",
    "    )\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def torch_sample(means_, covariances_, weights_, n_samples):\n",
    "    # Set up the random generator with a specified seed\n",
    "    generator = torch.Generator().manual_seed(RANDOM_STATE)\n",
    "    \n",
    "    # Sample component counts from the multinomial distribution\n",
    "    n_samples_comp = torch.multinomial(weights_, n_samples, replacement=True, generator=generator).bincount(minlength=len(weights_))\n",
    "    \n",
    "    # Initialize lists to collect samples and labels\n",
    "    X = []\n",
    "    y = []\n",
    "    \n",
    "    # Sample from each component based on the number of samples\n",
    "    for j, (mean, covariance, sample_count) in enumerate(zip(means_, covariances_, n_samples_comp)):\n",
    "        if sample_count > 0:  # Only sample if we need samples from this component\n",
    "            dist = torch.distributions.MultivariateNormal(\n",
    "                mean, covariance\n",
    "            )\n",
    "            samples = dist.sample((sample_count,))\n",
    "            X.append(samples)\n",
    "            y.append(torch.full((sample_count,), j, dtype=torch.int64))\n",
    "    \n",
    "    # Concatenate all samples and labels into single tensors\n",
    "    X = torch.vstack(X)\n",
    "    y = torch.cat(y)\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.07240839, -1.71829723, -0.60803314,  1.73979589,  2.01262296,\n",
       "         0.11960121, -0.18303798,  2.26989082, -0.18918716, -3.64823518,\n",
       "        -0.51437723, -1.0090173 , -1.70681869,  0.34972181,  2.84867092,\n",
       "        -2.27103036,  2.52582455,  3.44432533]),\n",
       " 0)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm_samples = sample(skgmm.means_, skgmm.covariances_, skgmm.weights_, n_samples = N_SAMPLES)\n",
    "\n",
    "skgmm_X, skgmm_y = skgmm_samples\n",
    "skgmm_X[IDX], skgmm_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.4047585 , -2.01683898, -1.32529041,  2.77408286,  1.82210771,\n",
       "         0.06704174, -1.10510541,  2.33170647, -0.58834022, -3.6683143 ,\n",
       "        -0.97818583, -2.3354214 , -1.63901546,  0.05558079,  2.33957331,\n",
       "        -2.19347763,  5.54049101,  1.08385274]),\n",
       " 0)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = sample(means, covar, weights, n_samples = N_SAMPLES)\n",
    "\n",
    "X, y = samples\n",
    "X[IDX], y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ -5.0416, -30.0005,  24.1288, -27.3287,   5.9395,   1.1542,  22.8423,\n",
       "         -22.7208,   1.2230, -27.2587,  25.5793,  40.1886,  45.4400,  -4.1804,\n",
       "          34.8146, -36.0102,   7.2540,   0.3268]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_samples = torch_sample(trained_model.means, trained_model.covariances, trained_model.weights, n_samples = N_SAMPLES)\n",
    "train_model_X, train_model_y = train_model_samples\n",
    "train_model_X[IDX], train_model_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ -5.0416, -30.0005,  24.1288, -27.3287,   5.9395,   1.1542,  22.8423,\n",
       "         -22.7208,   1.2230, -27.2587,  25.5793,  40.1886,  45.4400,  -4.1804,\n",
       "          34.8146, -36.0102,   7.2540,   0.3268]),\n",
       " tensor(1))"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_samples = torch_sample(gmm_lightning_module.gmm_module.means, gmm_lightning_module.gmm_module.covariances, gmm_lightning_module.gmm_module.weights, n_samples = N_SAMPLES)\n",
    "gmm_lightning_X, gmm_lightning_y = train_model_samples\n",
    "gmm_lightning_X[IDX], gmm_lightning_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSynth-BNsxhSIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
