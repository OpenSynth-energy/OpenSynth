{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "full_data = pd.read_csv(\"../../data/processed/historical/train/lcl_data.csv\")\n",
    "df_100K = full_data.sample(100000, random_state=0)\n",
    "df_100K.to_csv(\"../../data/processed/historical/train/lcl_data_100K.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import random\n",
    "RANDOM_STATE = 0\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.use_deterministic_algorithms(True)\n",
    "g = torch.Generator()\n",
    "g.manual_seed(RANDOM_STATE)\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "    worker_seed = torch.initial_seed() % 2**32\n",
    "    np.random.seed(worker_seed)\n",
    "    random.seed(worker_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from opensynth.data_modules.lcl_data_module import LCLDataModule\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data_path = Path(\"../../data/processed/historical/train/lcl_data_25K.csv\")\n",
    "stats_path = Path(\"../../data/processed/historical/train/mean_std.csv\")\n",
    "outlier_path = Path(\"../../data/processed/historical/train/outliers.csv\")\n",
    "\n",
    "dm = LCLDataModule(data_path=data_path, stats_path=stats_path, batch_size=25000, n_samples=25000)\n",
    "dm.setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FaradayVAE(\n",
       "  (encoder): Encoder(\n",
       "    (encoder_layers): Sequential(\n",
       "      (0): Linear(in_features=50, out_features=512, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=512, out_features=256, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=256, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=64, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=64, out_features=32, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=32, out_features=16, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (latent): Linear(in_features=18, out_features=16, bias=True)\n",
       "    (latent_activations): GELU(approximate='none')\n",
       "    (decoder_layers): Sequential(\n",
       "      (0): Linear(in_features=16, out_features=32, bias=True)\n",
       "      (1): GELU(approximate='none')\n",
       "      (2): Linear(in_features=32, out_features=64, bias=True)\n",
       "      (3): GELU(approximate='none')\n",
       "      (4): Linear(in_features=64, out_features=128, bias=True)\n",
       "      (5): GELU(approximate='none')\n",
       "      (6): Linear(in_features=128, out_features=256, bias=True)\n",
       "      (7): GELU(approximate='none')\n",
       "      (8): Linear(in_features=256, out_features=512, bias=True)\n",
       "      (9): GELU(approximate='none')\n",
       "      (10): Linear(in_features=512, out_features=48, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (reparametriser): ReparametrisationModule(\n",
       "    (mean): Linear(in_features=16, out_features=16, bias=True)\n",
       "    (logvar): Linear(in_features=16, out_features=16, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from opensynth.models.faraday import FaradayVAE\n",
    "vae_model = torch.load(\"vae_model.pt\")\n",
    "vae_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "from opensynth.models.faraday.gaussian_mixture.prepare_gmm_input import encode_data_for_gmm\n",
    "\n",
    "next_batch = next(iter(dm.train_dataloader()))\n",
    "input_tensor = encode_data_for_gmm(data=next_batch, vae_module=vae_model)\n",
    "input_data = input_tensor.detach().numpy()\n",
    "n_samples = len(input_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_COMPONENTS = 250\n",
    "REG_COVAR = 1e-4\n",
    "EPOCHS = 25\n",
    "IDX = 0\n",
    "CONVERGENCE_TOL = 1e-2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0195, grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Init GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.float32 torch.float32 torch.float32\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm import gmm_utils\n",
    "\n",
    "labels_, means_, responsibilities_ = gmm_utils.initialise_centroids(\n",
    "        X=input_data, n_components=N_COMPONENTS\n",
    "    )\n",
    "print(labels_.dtype, responsibilities_.dtype, means_.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (True, tensor(True))\n",
      "tensor(4.1672)\n",
      "tensor(1.)\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "print(gmm_init_params[\"precision_cholesky\"][IDX][0][0])\n",
    "print(gmm_init_params[\"weights\"].sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch GMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (True, tensor(True))\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 1/25 [00:00<00:18,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: inf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 2/25 [00:01<00:19,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.5455737113952637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 3/25 [00:02<00:15,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.23595058917999268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 4/25 [00:03<00:15,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.1542905569076538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [00:03<00:16,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.11812639236450195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 6/25 [00:04<00:13,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.09741419553756714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 7/25 [00:04<00:11,  1.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.08560162782669067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 8/25 [00:05<00:09,  1.75it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.07493609189987183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 9/25 [00:05<00:07,  2.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.0600125789642334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [00:06<00:06,  2.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.04927009344100952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 11/25 [00:06<00:05,  2.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.04166579246520996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 12/25 [00:06<00:05,  2.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.03287696838378906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 13/25 [00:07<00:05,  2.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.026912033557891846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 14/25 [00:07<00:04,  2.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.02238285541534424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [00:07<00:03,  2.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.01896977424621582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 16/25 [00:08<00:03,  2.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.015812456607818604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 17/25 [00:08<00:02,  3.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.01478499174118042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 18/25 [00:08<00:02,  3.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.012155234813690186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [00:09<00:02,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.010511398315429688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 19/25 [00:09<00:03,  1.99it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid covariance: (False, tensor(True))\n",
      "Change: 0.008294880390167236\n",
      "Converged: True. Number of iterations: 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.train_gmm import initialise_gmm_params, training_loop\n",
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureModel\n",
    "\n",
    "\n",
    "gmm_init_params = initialise_gmm_params(\n",
    "    X=input_data,\n",
    "    n_components = N_COMPONENTS,\n",
    "    reg_covar=REG_COVAR,\n",
    ")\n",
    "torch_gmm = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "torch_gmm.initialise(gmm_init_params)\n",
    "trained_model = training_loop(model=torch_gmm, data=input_tensor, max_iter=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Manual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import logsumexp\n",
    "from scipy import linalg\n",
    "\n",
    "def _estimate_gaussian_parameters(X, resp, reg_covar=REG_COVAR):\n",
    "    nk = resp.sum(axis=0) + 10 * np.finfo(resp.dtype).eps\n",
    "    means = np.dot(resp.T, X) / nk[:, np.newaxis]\n",
    "    n_components, n_features = means.shape\n",
    "    covariances = np.empty((n_components, n_features, n_features))\n",
    "    for k in range(n_components):\n",
    "        diff = X - means[k]\n",
    "        covariances[k] = np.dot(resp[:, k] * diff.T, diff) / nk[k]\n",
    "        covariances[k].flat[:: n_features + 1] += reg_covar\n",
    "    return nk, means, covariances\n",
    "\n",
    "def _compute_precision_cholesky(covariances):\n",
    "    estimate_precision_error_message = (\n",
    "        \"Fitting the mixture model failed because some components have \"\n",
    "        \"ill-defined empirical covariance (for instance caused by singleton \"\n",
    "        \"or collapsed samples). Try to decrease the number of components, \"\n",
    "        \"or increase reg_covar.\"\n",
    "    )\n",
    "\n",
    "    n_components, n_features, _ = covariances.shape\n",
    "    precisions_chol = np.empty((n_components, n_features, n_features))\n",
    "    for k, covariance in enumerate(covariances):\n",
    "        try:\n",
    "            cov_chol = linalg.cholesky(covariance, lower=True)\n",
    "        except linalg.LinAlgError:\n",
    "            raise ValueError(estimate_precision_error_message)\n",
    "        precisions_chol[k] = linalg.solve_triangular(\n",
    "            cov_chol, np.eye(n_features), lower=True\n",
    "        ).T\n",
    "    return precisions_chol\n",
    "\n",
    "def _compute_log_det_cholesky(matrix_chol, n_features):\n",
    "    n_components, _, _ = matrix_chol.shape\n",
    "    log_det_chol = np.sum(\n",
    "        np.log(matrix_chol.reshape(n_components, -1)[:, :: n_features + 1]), 1\n",
    "    )\n",
    "    return log_det_chol\n",
    "\n",
    "def _estimate_log_gaussian_prob(X, means, precisions_chol):\n",
    "    n_samples, n_features = X.shape\n",
    "    n_components, _ = means.shape\n",
    "\n",
    "    log_det = _compute_log_det_cholesky(precisions_chol, n_features)\n",
    "\n",
    "    log_prob = np.empty((n_samples, n_components))\n",
    "    for k, (mu, prec_chol) in enumerate(zip(means, precisions_chol)):\n",
    "        y = np.dot(X, prec_chol) - np.dot(mu, prec_chol)\n",
    "        log_prob[:, k] = np.sum(np.square(y), axis=1)\n",
    "    return -0.5 * (n_features * np.log(2 * np.pi) + log_prob) + log_det\n",
    "\n",
    "def _estimate_log_weights(weights):\n",
    "        return np.log(weights)\n",
    "\n",
    "def _estimate_weighted_log_prob(X, means, precisions_chol, weights):\n",
    "        return _estimate_log_gaussian_prob(X, means, precisions_chol) + _estimate_log_weights(weights)\n",
    "\n",
    "\n",
    "def _estimate_log_prob_resp(X, means, precisions_chol, weights):\n",
    "    weighted_log_prob = _estimate_weighted_log_prob(X, means, precisions_chol, weights)\n",
    "    log_prob_norm = logsumexp(weighted_log_prob, axis=1)\n",
    "    with np.errstate(under=\"ignore\"):\n",
    "        log_resp = weighted_log_prob - log_prob_norm[:, np.newaxis]\n",
    "    return log_prob_norm, log_resp\n",
    "\n",
    "def _e_step(X,means, precisions_chol, weights):\n",
    "    log_prob_norm, log_resp = _estimate_log_prob_resp(X, means, precisions_chol, weights)\n",
    "    return np.mean(log_prob_norm), log_resp\n",
    "\n",
    "def _m_step(X, log_reponsibilities, reg_covar=REG_COVAR):\n",
    "\n",
    "    weights_, means_, covariances_ = _estimate_gaussian_parameters(X,np.exp(log_reponsibilities),reg_covar=reg_covar)\n",
    "    weights_ /= weights_.sum()\n",
    "\n",
    "    precision_cholesky_ = _compute_precision_cholesky(covariances=covariances_)\n",
    "\n",
    "    return precision_cholesky_, weights_, means_, covariances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 4.167169570922852. Initial mean: 0.18039406836032867\n",
      "Old Prec Chol: 4.167169570922852. Old means: 0.18039406836032867\n",
      "New prec chol: 4.240417114097165. New means: 0.1610282390352588\n",
      "Change: inf\n",
      "Old Prec Chol: 4.240417114097165. Old means: 0.1610282390352588\n",
      "New prec chol: 4.289415021363738. New means: 0.13732364273655587\n",
      "Change: 0.545201791854862\n",
      "Old Prec Chol: 4.289415021363738. Old means: 0.13732364273655587\n",
      "New prec chol: 4.179746626419131. New means: 0.11500928863101198\n",
      "Change: 0.23580703880669862\n",
      "Old Prec Chol: 4.179746626419131. Old means: 0.11500928863101198\n",
      "New prec chol: 3.948317806998173. New means: 0.0940242050240092\n",
      "Change: 0.15423102791465793\n",
      "Old Prec Chol: 3.948317806998173. Old means: 0.0940242050240092\n",
      "New prec chol: 3.825919235870529. New means: 0.0780048305143228\n",
      "Change: 0.11806440901075788\n",
      "Old Prec Chol: 3.825919235870529. Old means: 0.0780048305143228\n",
      "New prec chol: 3.7660081759677153. New means: 0.0639742435193366\n",
      "Change: 0.09738448263012867\n",
      "Old Prec Chol: 3.7660081759677153. Old means: 0.0639742435193366\n",
      "New prec chol: 3.7084966573991913. New means: 0.05437675199400096\n",
      "Change: 0.08558614531543862\n",
      "Old Prec Chol: 3.7084966573991913. Old means: 0.05437675199400096\n",
      "New prec chol: 3.6994178709271104. New means: 0.04781638950152437\n",
      "Change: 0.07490936752352617\n",
      "Old Prec Chol: 3.6994178709271104. Old means: 0.04781638950152437\n",
      "New prec chol: 3.751819341359391. New means: 0.038677405861098385\n",
      "Change: 0.059997826466563375\n",
      "Old Prec Chol: 3.751819341359391. Old means: 0.038677405861098385\n",
      "New prec chol: 3.822284732792441. New means: 0.02814440736900492\n",
      "Change: 0.0492181455110694\n",
      "Old Prec Chol: 3.822284732792441. Old means: 0.02814440736900492\n",
      "New prec chol: 3.8328487534371463. New means: 0.022160361378782738\n",
      "Change: 0.04162639380555255\n",
      "Old Prec Chol: 3.8328487534371463. Old means: 0.022160361378782738\n",
      "New prec chol: 3.8219296631541804. New means: 0.018530019016977504\n",
      "Change: 0.03285203278012594\n",
      "Old Prec Chol: 3.8219296631541804. Old means: 0.018530019016977504\n",
      "New prec chol: 3.8064745870491636. New means: 0.015464889938143432\n",
      "Change: 0.026963020597311704\n",
      "Old Prec Chol: 3.8064745870491636. Old means: 0.015464889938143432\n",
      "New prec chol: 3.7918246030281204. New means: 0.012155923748701695\n",
      "Change: 0.02241627728850515\n",
      "Old Prec Chol: 3.7918246030281204. Old means: 0.012155923748701695\n",
      "New prec chol: 3.785281393856495. New means: 0.009394724807606232\n",
      "Change: 0.018976561322369134\n",
      "Old Prec Chol: 3.785281393856495. Old means: 0.009394724807606232\n",
      "New prec chol: 3.7800238216666724. New means: 0.007778703885397002\n",
      "Change: 0.015962454132842807\n",
      "Old Prec Chol: 3.7800238216666724. Old means: 0.007778703885397002\n",
      "New prec chol: 3.7788488031399803. New means: 0.007616895689466276\n",
      "Change: 0.014803540433677709\n",
      "Old Prec Chol: 3.7788488031399803. Old means: 0.007616895689466276\n",
      "New prec chol: 3.792387516917481. New means: 0.006902989095804807\n",
      "Change: 0.012056758932449063\n",
      "Old Prec Chol: 3.792387516917481. Old means: 0.006902989095804807\n",
      "New prec chol: 3.8191106455305537. New means: 0.005506209623379824\n",
      "Change: 0.010542964793586851\n",
      "Old Prec Chol: 3.8191106455305537. Old means: 0.005506209623379824\n",
      "New prec chol: 3.8498121421887257. New means: 0.0034967758850676226\n",
      "Change: 0.008311437252198406\n",
      "Converged: True. Number of iterations: 19\n"
     ]
    }
   ],
   "source": [
    "means = gmm_init_params[\"means\"].detach().numpy()\n",
    "weights = gmm_init_params[\"weights\"].detach().numpy()\n",
    "prec_chol = gmm_init_params[\"precision_cholesky\"].detach().numpy()\n",
    "\n",
    "print(f\"Initial prec chol: {prec_chol[IDX][0][0]}. Initial mean: {means[IDX][0]}\")\n",
    "\n",
    "converged = False\n",
    "lower_bound = -np.inf\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    prev_lower_bound = lower_bound\n",
    "\n",
    "    print(f\"Old Prec Chol: {prec_chol[IDX][0][0]}. Old means: {means[IDX][0]}\")\n",
    "    log_prob, log_resp = _e_step(input_data, means, prec_chol, weights)\n",
    "    prec_chol, weights, means, covar = _m_step(input_data, log_resp)\n",
    "\n",
    "    print(f\"New prec chol: {prec_chol[IDX][0][0]}. New means: {means[IDX][0]}\")\n",
    "\n",
    "    # Converegence\n",
    "    lower_bound = log_prob\n",
    "    change = abs(lower_bound - prev_lower_bound)\n",
    "    print(f\"Change: {change}\")\n",
    "    if change < CONVERGENCE_TOL:\n",
    "        converged = True\n",
    "        break\n",
    "\n",
    "print(f'Converged: {converged}. Number of iterations: {i}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SK Learn GMM Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization 0\n",
      "  Iteration 1\t time lapse 4.49572s\t ll change inf\n",
      "  Iteration 2\t time lapse 1.99019s\t ll change 0.55425\n",
      "  Iteration 3\t time lapse 2.10942s\t ll change 0.24330\n",
      "  Iteration 4\t time lapse 1.90294s\t ll change 0.16184\n",
      "  Iteration 5\t time lapse 2.04430s\t ll change 0.12116\n",
      "  Iteration 6\t time lapse 1.91540s\t ll change 0.10078\n",
      "  Iteration 7\t time lapse 2.20269s\t ll change 0.08830\n",
      "  Iteration 8\t time lapse 1.84719s\t ll change 0.07739\n",
      "  Iteration 9\t time lapse 2.01203s\t ll change 0.06126\n",
      "  Iteration 10\t time lapse 2.27183s\t ll change 0.04845\n",
      "  Iteration 11\t time lapse 2.16001s\t ll change 0.04266\n",
      "  Iteration 12\t time lapse 2.42154s\t ll change 0.03660\n",
      "  Iteration 13\t time lapse 2.35852s\t ll change 0.02900\n",
      "  Iteration 14\t time lapse 2.49654s\t ll change 0.02518\n",
      "  Iteration 15\t time lapse 3.23633s\t ll change 0.02246\n",
      "  Iteration 16\t time lapse 2.54810s\t ll change 0.01872\n",
      "  Iteration 17\t time lapse 2.47835s\t ll change 0.01665\n",
      "  Iteration 18\t time lapse 2.25658s\t ll change 0.01431\n",
      "  Iteration 19\t time lapse 2.16833s\t ll change 0.01274\n",
      "  Iteration 20\t time lapse 2.46885s\t ll change 0.01103\n",
      "  Iteration 21\t time lapse 2.32197s\t ll change 0.01034\n",
      "  Iteration 22\t time lapse 2.58331s\t ll change 0.00865\n",
      "Initialization converged. time lapse 52.29472s\t lower bound 0.09028.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.mixture import GaussianMixture\n",
    "\n",
    "init_weights = gmm_init_params[\"weights\"]\n",
    "init_means = gmm_init_params[\"means\"]\n",
    "\n",
    "skgmm = GaussianMixture(n_components=N_COMPONENTS, covariance_type='full', tol=CONVERGENCE_TOL, max_iter=EPOCHS, random_state=0, means_init = init_means, weights_init=init_weights, verbose=2, verbose_interval=1)\n",
    "skgmm.fit(input_data)\n",
    "skgmm_pred = skgmm.predict(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, 22)"
      ]
     },
     "execution_count": 194,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm.converged_, skgmm.n_iter_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Torch Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from pytorch_lightning import LightningDataModule\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_tensor: torch.Tensor):\n",
    "        self.data = data_tensor\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.data[idx]\n",
    "    \n",
    "class CustomDataModule(LightningDataModule):\n",
    "    def __init__(self, data_tensor: torch.Tensor, batch_size: int):\n",
    "        super().__init__()\n",
    "        self.data_tensor = data_tensor\n",
    "        self.batch_size = batch_size\n",
    "    def setup(self, stage=\"\"):\n",
    "        self.custom_ds = CustomDataset(self.data_tensor)\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(self.custom_ds, batch_size=self.batch_size, shuffle=False, generator=g, worker_init_fn=seed_worker)\n",
    "    \n",
    "custom_dm = CustomDataModule(data_tensor=input_tensor, batch_size=25000)\n",
    "custom_dm.setup(stage=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n",
      "tensor(0.0195, grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(5):\n",
    "    print(next(iter(custom_dm.train_dataloader()))[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/setup.py:177: GPU available but not used. You can set it by doing `Trainer(accelerator='gpu')`.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/core/optimizer.py:182: `LightningModule.configure_optimizers` returned `None`, this fit will run with no optimizer\n",
      "\n",
      "  | Name                      | Type                    | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | gmm_module                | GaussianMixtureModel    | 0      | train\n",
      "1 | vae_module                | FaradayVAE              | 402 K  | eval \n",
      "2 | weight_metric             | WeightsMetric           | 0      | train\n",
      "3 | mean_metric               | MeansMetric             | 0      | train\n",
      "4 | precision_cholesky_metric | PrecisionCholeskyMetric | 0      | train\n",
      "5 | covariance_metric         | CovarianceMetric        | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "402 K     Trainable params\n",
      "0         Non-trainable params\n",
      "402 K     Total params\n",
      "1.609     Total estimated model params size (MB)\n",
      "5         Modules in train mode\n",
      "32        Modules in eval mode\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:424: The 'train_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=7` in the `DataLoader` to improve performance.\n",
      "/Users/charlotte.avery/.virtualenvs/OpenSynth-BNsxhSIM/lib/python3.11/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (1) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prec chol: 4.167169570922852. Initial mean: 0.18039406836032867\n",
      "Epoch 0:   0%|          | 0/1 [00:00<?, ?it/s] Valid covariance: (False, tensor(True))\n",
      "Epoch 0: 100%|██████████| 1/1 [00:00<00:00,  1.32it/s, v_num=27]Local weights at rank: 0 - means: 0.0062, 0.1610\n",
      "Reduced weights, means: 0.0062, 0.1610\n",
      "Epoch 1:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 1: 100%|██████████| 1/1 [00:00<00:00,  2.46it/s, v_num=27]Local weights at rank: 0 - means: 0.0058, 0.1373\n",
      "Reduced weights, means: 0.0058, 0.1373\n",
      "Epoch 2:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 2: 100%|██████████| 1/1 [00:00<00:00,  2.70it/s, v_num=27]Local weights at rank: 0 - means: 0.0057, 0.1149\n",
      "Reduced weights, means: 0.0057, 0.1149\n",
      "Epoch 3:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 3: 100%|██████████| 1/1 [00:00<00:00,  2.99it/s, v_num=27]Local weights at rank: 0 - means: 0.0057, 0.0939\n",
      "Reduced weights, means: 0.0057, 0.0939\n",
      "Epoch 4:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 4: 100%|██████████| 1/1 [00:00<00:00,  2.43it/s, v_num=27]Local weights at rank: 0 - means: 0.0054, 0.0779\n",
      "Reduced weights, means: 0.0054, 0.0779\n",
      "Epoch 5:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 5: 100%|██████████| 1/1 [00:00<00:00,  2.82it/s, v_num=27]Local weights at rank: 0 - means: 0.0052, 0.0639\n",
      "Reduced weights, means: 0.0052, 0.0639\n",
      "Epoch 6:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 6: 100%|██████████| 1/1 [00:00<00:00,  1.81it/s, v_num=27]Local weights at rank: 0 - means: 0.0049, 0.0545\n",
      "Reduced weights, means: 0.0049, 0.0545\n",
      "Epoch 7:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 7: 100%|██████████| 1/1 [00:00<00:00,  2.40it/s, v_num=27]Local weights at rank: 0 - means: 0.0048, 0.0480\n",
      "Reduced weights, means: 0.0048, 0.0480\n",
      "Epoch 8:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 8: 100%|██████████| 1/1 [00:00<00:00,  2.56it/s, v_num=27]Local weights at rank: 0 - means: 0.0047, 0.0388\n",
      "Reduced weights, means: 0.0047, 0.0388\n",
      "Epoch 9:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 9: 100%|██████████| 1/1 [00:00<00:00,  1.51it/s, v_num=27]Local weights at rank: 0 - means: 0.0046, 0.0284\n",
      "Reduced weights, means: 0.0046, 0.0284\n",
      "Epoch 10:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]       Valid covariance: (False, tensor(True))\n",
      "Epoch 10: 100%|██████████| 1/1 [00:00<00:00,  1.70it/s, v_num=27]Local weights at rank: 0 - means: 0.0047, 0.0225\n",
      "Reduced weights, means: 0.0047, 0.0225\n",
      "Epoch 11:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 11: 100%|██████████| 1/1 [00:00<00:00,  1.82it/s, v_num=27]Local weights at rank: 0 - means: 0.0047, 0.0188\n",
      "Reduced weights, means: 0.0047, 0.0188\n",
      "Epoch 12:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 12: 100%|██████████| 1/1 [00:00<00:00,  2.24it/s, v_num=27]Local weights at rank: 0 - means: 0.0047, 0.0156\n",
      "Reduced weights, means: 0.0047, 0.0156\n",
      "Epoch 13:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 13: 100%|██████████| 1/1 [00:00<00:00,  3.04it/s, v_num=27]Local weights at rank: 0 - means: 0.0047, 0.0122\n",
      "Reduced weights, means: 0.0047, 0.0122\n",
      "Epoch 14:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 14: 100%|██████████| 1/1 [00:00<00:00,  1.58it/s, v_num=27]Local weights at rank: 0 - means: 0.0046, 0.0094\n",
      "Reduced weights, means: 0.0046, 0.0094\n",
      "Epoch 15:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 15: 100%|██████████| 1/1 [00:00<00:00,  2.96it/s, v_num=27]Local weights at rank: 0 - means: 0.0045, 0.0079\n",
      "Reduced weights, means: 0.0045, 0.0079\n",
      "Epoch 16:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 16: 100%|██████████| 1/1 [00:00<00:00,  2.07it/s, v_num=27]Local weights at rank: 0 - means: 0.0045, 0.0078\n",
      "Reduced weights, means: 0.0045, 0.0078\n",
      "Epoch 17:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 17: 100%|██████████| 1/1 [00:00<00:00,  2.69it/s, v_num=27]Local weights at rank: 0 - means: 0.0044, 0.0073\n",
      "Reduced weights, means: 0.0044, 0.0073\n",
      "Epoch 18:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 18: 100%|██████████| 1/1 [00:00<00:00,  3.02it/s, v_num=27]Local weights at rank: 0 - means: 0.0043, 0.0058\n",
      "Reduced weights, means: 0.0043, 0.0058\n",
      "Epoch 19:   0%|          | 0/1 [00:00<?, ?it/s, v_num=27]        Valid covariance: (False, tensor(True))\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.63it/s, v_num=27]Local weights at rank: 0 - means: 0.0042, 0.0035\n",
      "Reduced weights, means: 0.0042, 0.0035\n",
      "Epoch 19: 100%|██████████| 1/1 [00:00<00:00,  2.47it/s, v_num=27]\n"
     ]
    }
   ],
   "source": [
    "from opensynth.models.faraday.new_gmm.new_gmm_model import GaussianMixtureLightningModule\n",
    "gmm_module = GaussianMixtureModel(\n",
    "    num_components=N_COMPONENTS,\n",
    "    num_features = input_data.shape[1],\n",
    "    reg_covar=REG_COVAR,\n",
    "    print_idx=IDX\n",
    ")\n",
    "gmm_module.initialise(gmm_init_params)\n",
    "print(f\"Initial prec chol: {gmm_module.precision_cholesky[IDX][0][0]}. Initial mean: {gmm_module.means[IDX][0]}\")\n",
    "\n",
    "gmm_lightning_module = GaussianMixtureLightningModule(\n",
    "    gmm_module = gmm_module,\n",
    "    vae_module = vae_model,\n",
    "    num_components = gmm_module.num_components,\n",
    "    num_features = gmm_module.num_features,\n",
    "    reg_covar = gmm_module.reg_covar,\n",
    "    convergence_tolerance = CONVERGENCE_TOL\n",
    ")\n",
    "trainer = pl.Trainer(max_epochs=EPOCHS, accelerator=\"cpu\", deterministic=True )\n",
    "trainer.fit(gmm_lightning_module, custom_dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0042), tensor(0.0035))"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_module.gmm_module.weights[0], gmm_lightning_module.gmm_module.means[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(0.0042), tensor(0.0035))"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_module.weight_metric.compute()[0], gmm_lightning_module.mean_metric.compute()[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "IDX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.034104</td>\n",
       "      <td>0.003497</td>\n",
       "      <td>0.003455</td>\n",
       "      <td>0.003455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.555318</td>\n",
       "      <td>-1.622721</td>\n",
       "      <td>-1.625163</td>\n",
       "      <td>-1.625163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.805133</td>\n",
       "      <td>-0.963266</td>\n",
       "      <td>-0.962647</td>\n",
       "      <td>-0.962647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.467063</td>\n",
       "      <td>1.691928</td>\n",
       "      <td>1.693601</td>\n",
       "      <td>1.693601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.521913</td>\n",
       "      <td>0.539403</td>\n",
       "      <td>0.543288</td>\n",
       "      <td>0.543288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-0.079050</td>\n",
       "      <td>-0.085705</td>\n",
       "      <td>-0.085293</td>\n",
       "      <td>-0.085293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.479725</td>\n",
       "      <td>-0.688806</td>\n",
       "      <td>-0.688216</td>\n",
       "      <td>-0.688216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3.150586</td>\n",
       "      <td>3.294430</td>\n",
       "      <td>3.298344</td>\n",
       "      <td>3.298344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.261914</td>\n",
       "      <td>-0.301814</td>\n",
       "      <td>-0.301562</td>\n",
       "      <td>-0.301562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-1.601044</td>\n",
       "      <td>-1.791389</td>\n",
       "      <td>-1.798772</td>\n",
       "      <td>-1.798772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.420805</td>\n",
       "      <td>-0.596436</td>\n",
       "      <td>-0.595341</td>\n",
       "      <td>-0.595341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-1.321161</td>\n",
       "      <td>-1.473653</td>\n",
       "      <td>-1.472831</td>\n",
       "      <td>-1.472831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-2.275731</td>\n",
       "      <td>-2.320777</td>\n",
       "      <td>-2.323202</td>\n",
       "      <td>-2.323202</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.972640</td>\n",
       "      <td>0.932376</td>\n",
       "      <td>0.934154</td>\n",
       "      <td>0.934154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.117066</td>\n",
       "      <td>1.100251</td>\n",
       "      <td>1.106312</td>\n",
       "      <td>1.106312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-1.158142</td>\n",
       "      <td>-1.231581</td>\n",
       "      <td>-1.235144</td>\n",
       "      <td>-1.235144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>7.208155</td>\n",
       "      <td>7.501894</td>\n",
       "      <td>7.508543</td>\n",
       "      <td>7.508543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2.889751</td>\n",
       "      <td>2.853175</td>\n",
       "      <td>2.850810</td>\n",
       "      <td>2.850810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0  -0.034104  0.003497  0.003455   0.003455\n",
       "1  -1.555318 -1.622721 -1.625163  -1.625163\n",
       "2  -0.805133 -0.963266 -0.962647  -0.962647\n",
       "3   1.467063  1.691928  1.693601   1.693601\n",
       "4   0.521913  0.539403  0.543288   0.543288\n",
       "5  -0.079050 -0.085705 -0.085293  -0.085293\n",
       "6  -0.479725 -0.688806 -0.688216  -0.688216\n",
       "7   3.150586  3.294430  3.298344   3.298344\n",
       "8  -0.261914 -0.301814 -0.301562  -0.301562\n",
       "9  -1.601044 -1.791389 -1.798772  -1.798772\n",
       "10 -0.420805 -0.596436 -0.595341  -0.595341\n",
       "11 -1.321161 -1.473653 -1.472831  -1.472831\n",
       "12 -2.275731 -2.320777 -2.323202  -2.323202\n",
       "13  0.972640  0.932376  0.934154   0.934154\n",
       "14  1.117066  1.100251  1.106312   1.106312\n",
       "15 -1.158142 -1.231581 -1.235144  -1.235144\n",
       "16  7.208155  7.501894  7.508543   7.508543\n",
       "17  2.889751  2.853175  2.850810   2.850810"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_means = pd.DataFrame()\n",
    "df_compare_means[\"skgmm\"] = skgmm.means_[IDX]\n",
    "df_compare_means[\"numpy\"] = means[IDX]\n",
    "df_compare_means[\"torch\"] = trained_model.means[IDX]\n",
    "df_compare_means[\"lightning\"] = gmm_lightning_module.gmm_module.means[IDX]\n",
    "df_compare_means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.1804, -2.7538, -1.0911,  1.7346,  0.2788, -0.0517, -0.9778,  3.2770,\n",
       "        -0.2799, -2.2817, -0.6563, -1.5545, -1.2570,  0.9383,  0.9554, -2.0788,\n",
       "         5.9050,  3.9497])"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_init_params[\"means\"][IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.078326</td>\n",
       "      <td>0.067472</td>\n",
       "      <td>0.067431</td>\n",
       "      <td>0.067431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.199605</td>\n",
       "      <td>-0.186681</td>\n",
       "      <td>-0.187432</td>\n",
       "      <td>-0.187432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.112370</td>\n",
       "      <td>-0.087543</td>\n",
       "      <td>-0.087666</td>\n",
       "      <td>-0.087666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.118446</td>\n",
       "      <td>0.097261</td>\n",
       "      <td>0.097659</td>\n",
       "      <td>0.097659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002640</td>\n",
       "      <td>0.005331</td>\n",
       "      <td>0.005539</td>\n",
       "      <td>0.005539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.017543</td>\n",
       "      <td>0.011311</td>\n",
       "      <td>0.011351</td>\n",
       "      <td>0.011351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.130956</td>\n",
       "      <td>-0.112912</td>\n",
       "      <td>-0.113341</td>\n",
       "      <td>-0.113341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-0.064959</td>\n",
       "      <td>-0.090017</td>\n",
       "      <td>-0.089387</td>\n",
       "      <td>-0.089387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-0.017749</td>\n",
       "      <td>-0.016246</td>\n",
       "      <td>-0.016301</td>\n",
       "      <td>-0.016301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-0.043763</td>\n",
       "      <td>-0.068598</td>\n",
       "      <td>-0.069978</td>\n",
       "      <td>-0.069978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-0.068346</td>\n",
       "      <td>-0.061660</td>\n",
       "      <td>-0.061922</td>\n",
       "      <td>-0.061922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-0.228765</td>\n",
       "      <td>-0.184069</td>\n",
       "      <td>-0.183920</td>\n",
       "      <td>-0.183920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.186061</td>\n",
       "      <td>0.203703</td>\n",
       "      <td>0.203871</td>\n",
       "      <td>0.203871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-0.034581</td>\n",
       "      <td>-0.055859</td>\n",
       "      <td>-0.055803</td>\n",
       "      <td>-0.055803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.054618</td>\n",
       "      <td>-0.035360</td>\n",
       "      <td>-0.034876</td>\n",
       "      <td>-0.034876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-0.150734</td>\n",
       "      <td>-0.155213</td>\n",
       "      <td>-0.155903</td>\n",
       "      <td>-0.155903</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.043952</td>\n",
       "      <td>-0.049352</td>\n",
       "      <td>-0.050270</td>\n",
       "      <td>-0.050270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.045143</td>\n",
       "      <td>-0.021375</td>\n",
       "      <td>-0.022970</td>\n",
       "      <td>-0.022970</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       skgmm     numpy     torch  lightning\n",
       "0   0.078326  0.067472  0.067431   0.067431\n",
       "1  -0.199605 -0.186681 -0.187432  -0.187432\n",
       "2  -0.112370 -0.087543 -0.087666  -0.087666\n",
       "3   0.118446  0.097261  0.097659   0.097659\n",
       "4   0.002640  0.005331  0.005539   0.005539\n",
       "5   0.017543  0.011311  0.011351   0.011351\n",
       "6  -0.130956 -0.112912 -0.113341  -0.113341\n",
       "7  -0.064959 -0.090017 -0.089387  -0.089387\n",
       "8  -0.017749 -0.016246 -0.016301  -0.016301\n",
       "9  -0.043763 -0.068598 -0.069978  -0.069978\n",
       "10 -0.068346 -0.061660 -0.061922  -0.061922\n",
       "11 -0.228765 -0.184069 -0.183920  -0.183920\n",
       "12  0.186061  0.203703  0.203871   0.203871\n",
       "13 -0.034581 -0.055859 -0.055803  -0.055803\n",
       "14 -0.054618 -0.035360 -0.034876  -0.034876\n",
       "15 -0.150734 -0.155213 -0.155903  -0.155903\n",
       "16 -0.043952 -0.049352 -0.050270  -0.050270\n",
       "17  0.045143 -0.021375 -0.022970  -0.022970"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_covar = pd.DataFrame()\n",
    "df_compare_covar[\"skgmm\"] = skgmm.covariances_[IDX][0]\n",
    "df_compare_covar[\"numpy\"] = covar[IDX][0]\n",
    "df_compare_covar[\"torch\"] = trained_model.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar[\"lightning\"] = gmm_lightning_module.gmm_module.covariances.detach().numpy()[IDX][0]\n",
    "df_compare_covar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.573121</td>\n",
       "      <td>3.849812</td>\n",
       "      <td>3.850963</td>\n",
       "      <td>3.850963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.461067</td>\n",
       "      <td>2.455015</td>\n",
       "      <td>2.456105</td>\n",
       "      <td>2.456105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.998015</td>\n",
       "      <td>2.292612</td>\n",
       "      <td>2.290046</td>\n",
       "      <td>2.290046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.307495</td>\n",
       "      <td>-1.795725</td>\n",
       "      <td>-1.789544</td>\n",
       "      <td>-1.789544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-2.952195</td>\n",
       "      <td>-3.082288</td>\n",
       "      <td>-3.071050</td>\n",
       "      <td>-3.071050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-6.022596</td>\n",
       "      <td>-3.587201</td>\n",
       "      <td>-3.623628</td>\n",
       "      <td>-3.623628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2.662257</td>\n",
       "      <td>3.830740</td>\n",
       "      <td>3.820804</td>\n",
       "      <td>3.820804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>10.953345</td>\n",
       "      <td>12.415186</td>\n",
       "      <td>12.467817</td>\n",
       "      <td>12.467817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.997179</td>\n",
       "      <td>1.477781</td>\n",
       "      <td>1.524926</td>\n",
       "      <td>1.524926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-4.058303</td>\n",
       "      <td>-4.109881</td>\n",
       "      <td>-4.275584</td>\n",
       "      <td>-4.275584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.983002</td>\n",
       "      <td>2.767941</td>\n",
       "      <td>2.731329</td>\n",
       "      <td>2.731329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>3.366544</td>\n",
       "      <td>6.304832</td>\n",
       "      <td>6.525237</td>\n",
       "      <td>6.525237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.427880</td>\n",
       "      <td>-4.386695</td>\n",
       "      <td>-4.322817</td>\n",
       "      <td>-4.322817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-4.298348</td>\n",
       "      <td>-2.088699</td>\n",
       "      <td>-2.148988</td>\n",
       "      <td>-2.148988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>3.908085</td>\n",
       "      <td>5.135323</td>\n",
       "      <td>5.346714</td>\n",
       "      <td>5.346714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>5.325482</td>\n",
       "      <td>4.895979</td>\n",
       "      <td>4.864012</td>\n",
       "      <td>4.864012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.713790</td>\n",
       "      <td>3.335771</td>\n",
       "      <td>3.163535</td>\n",
       "      <td>3.163535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>5.823156</td>\n",
       "      <td>4.351387</td>\n",
       "      <td>4.394915</td>\n",
       "      <td>4.394915</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        skgmm      numpy      torch  lightning\n",
       "0    3.573121   3.849812   3.850963   3.850963\n",
       "1    2.461067   2.455015   2.456105   2.456105\n",
       "2    2.998015   2.292612   2.290046   2.290046\n",
       "3   -1.307495  -1.795725  -1.789544  -1.789544\n",
       "4   -2.952195  -3.082288  -3.071050  -3.071050\n",
       "5   -6.022596  -3.587201  -3.623628  -3.623628\n",
       "6    2.662257   3.830740   3.820804   3.820804\n",
       "7   10.953345  12.415186  12.467817  12.467817\n",
       "8    1.997179   1.477781   1.524926   1.524926\n",
       "9   -4.058303  -4.109881  -4.275584  -4.275584\n",
       "10   2.983002   2.767941   2.731329   2.731329\n",
       "11   3.366544   6.304832   6.525237   6.525237\n",
       "12  -5.427880  -4.386695  -4.322817  -4.322817\n",
       "13  -4.298348  -2.088699  -2.148988  -2.148988\n",
       "14   3.908085   5.135323   5.346714   5.346714\n",
       "15   5.325482   4.895979   4.864012   4.864012\n",
       "16   2.713790   3.335771   3.163535   3.163535\n",
       "17   5.823156   4.351387   4.394915   4.394915"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_pre_chol = pd.DataFrame()\n",
    "df_compare_pre_chol[\"skgmm\"] = skgmm.precisions_cholesky_[IDX][0]\n",
    "df_compare_pre_chol[\"numpy\"] = prec_chol[IDX][0]\n",
    "df_compare_pre_chol[\"torch\"] = trained_model.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol[\"lightning\"] = gmm_lightning_module.gmm_module.precision_cholesky.detach().numpy()[IDX][0]\n",
    "df_compare_pre_chol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>skgmm</th>\n",
       "      <th>numpy</th>\n",
       "      <th>torch</th>\n",
       "      <th>lightning</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.004755</td>\n",
       "      <td>0.004216</td>\n",
       "      <td>0.004236</td>\n",
       "      <td>0.004236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.029276</td>\n",
       "      <td>0.041534</td>\n",
       "      <td>0.041527</td>\n",
       "      <td>0.041527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.021889</td>\n",
       "      <td>0.022639</td>\n",
       "      <td>0.022607</td>\n",
       "      <td>0.022607</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002770</td>\n",
       "      <td>0.002551</td>\n",
       "      <td>0.002554</td>\n",
       "      <td>0.002554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "      <td>0.000160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.006458</td>\n",
       "      <td>0.005502</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.005507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.005356</td>\n",
       "      <td>0.005325</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.005326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>0.000600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "      <td>0.000480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      skgmm     numpy     torch  lightning\n",
       "0  0.004755  0.004216  0.004236   0.004236\n",
       "1  0.000160  0.000160  0.000160   0.000160\n",
       "2  0.029276  0.041534  0.041527   0.041527\n",
       "3  0.021889  0.022639  0.022607   0.022607\n",
       "4  0.002770  0.002551  0.002554   0.002554\n",
       "5  0.000160  0.000160  0.000160   0.000160\n",
       "6  0.006458  0.005502  0.005507   0.005507\n",
       "7  0.005356  0.005325  0.005326   0.005326\n",
       "8  0.000600  0.000600  0.000600   0.000600\n",
       "9  0.000480  0.000480  0.000480   0.000480"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_compare_weights = pd.DataFrame()\n",
    "df_compare_weights[\"skgmm\"] = skgmm.weights_[:10]\n",
    "df_compare_weights[\"numpy\"] = weights[:10]\n",
    "df_compare_weights[\"torch\"] = trained_model.weights[:10]\n",
    "df_compare_weights[\"lightning\"] = gmm_lightning_module.gmm_module.weights.detach().numpy()[:10]\n",
    "df_compare_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(means_, covariances_, weights_, n_samples):\n",
    "    rng = np.random.RandomState(RANDOM_STATE)\n",
    "    n_samples_comp = rng.multinomial(n_samples, weights_)\n",
    "\n",
    "    X = np.vstack(\n",
    "            [\n",
    "                rng.multivariate_normal(mean, covariance, int(sample))\n",
    "                for (mean, covariance, sample) in zip(\n",
    "                    means_, covariances_, n_samples_comp\n",
    "                )\n",
    "            ]\n",
    "        )\n",
    "    \n",
    "    y = np.concatenate(\n",
    "        [np.full(sample, j, dtype=int) for j, sample in enumerate(n_samples_comp)]\n",
    "    )\n",
    "    return (X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_SAMPLES = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.01564824, -2.48977325, -1.06677265,  1.03595019, -0.56687919,\n",
       "        -0.17060043, -0.5776165 ,  3.60625806, -0.09829001,  0.36356929,\n",
       "         0.21534989, -2.43721739, -2.06559949,  1.85034522, -0.18437695,\n",
       "        -0.96888118, 11.95730699,  3.74599508]),\n",
       " 0)"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "skgmm_samples = sample(skgmm.means_, skgmm.covariances_, skgmm.weights_, n_samples = N_SAMPLES)\n",
    "\n",
    "skgmm_X, skgmm_y = skgmm_samples\n",
    "skgmm_X[IDX], skgmm_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.18499373, -0.83446685, -0.60144353,  2.06066525,  2.49065299,\n",
       "         0.10429114, -0.31643926,  1.21047995, -0.52292939, -3.62534916,\n",
       "        -0.78782121, -1.43205912, -1.679075  , -0.43291366,  2.993503  ,\n",
       "        -1.81419148,  2.90864241,  3.34585713]),\n",
       " 0)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "samples = sample(means, covar, weights, n_samples = N_SAMPLES)\n",
    "\n",
    "X, y = samples\n",
    "X[IDX], y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2x1gj41j1xb5z153q5m_4rn80000gn/T/ipykernel_6913/1110536824.py:7: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  rng.multivariate_normal(mean, covariance, int(sample))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.1897325 , -0.88072923, -0.61986741,  2.07609162,  2.47815962,\n",
       "         0.10266462, -0.34256586,  1.2532853 , -0.52365649, -3.65412251,\n",
       "        -0.79721218, -1.43767327, -1.66040658, -0.42377924,  2.98937742,\n",
       "        -1.84510692,  2.90485408,  3.33865499]),\n",
       " 0)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_model_samples = sample(trained_model.means.detach().numpy(), trained_model.covariances.detach().numpy(), trained_model.weights.detach().numpy(), n_samples = N_SAMPLES)\n",
    "train_model_X, train_model_y = train_model_samples\n",
    "train_model_X[IDX], train_model_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/w2/2x1gj41j1xb5z153q5m_4rn80000gn/T/ipykernel_6913/1110536824.py:7: RuntimeWarning: covariance is not symmetric positive-semidefinite.\n",
      "  rng.multivariate_normal(mean, covariance, int(sample))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([ 0.1897325 , -0.88072923, -0.61986741,  2.07609162,  2.47815962,\n",
       "         0.10266462, -0.34256586,  1.2532853 , -0.52365649, -3.65412251,\n",
       "        -0.79721218, -1.43767327, -1.66040658, -0.42377924,  2.98937742,\n",
       "        -1.84510692,  2.90485408,  3.33865499]),\n",
       " 0)"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gmm_lightning_samples = sample(gmm_lightning_module.gmm_module.means.detach().numpy(), gmm_lightning_module.gmm_module.covariances.detach().numpy(), gmm_lightning_module.gmm_module.weights.detach().numpy(), n_samples = N_SAMPLES)\n",
    "gmm_lightning_X, gmm_lightning_y = train_model_samples\n",
    "gmm_lightning_X[IDX], gmm_lightning_y[IDX]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "OpenSynth-BNsxhSIM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
